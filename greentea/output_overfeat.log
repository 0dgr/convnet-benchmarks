I0417 00:33:39.500573 28773 caffe.cpp:212] Use GPU with device ID 0
E0417 00:33:39.698592 28773 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/overfeat.prototxt
E0417 00:33:39.698644 28773 upgrade_proto.cpp:636] Input NetParameter to be upgraded already specifies 'layer' fields; these will be ignored for the upgrade.
E0417 00:33:39.698678 28773 upgrade_proto.cpp:623] Warning: had one or more problems upgrading V1LayerParameter (see above); continuing anyway.
I0417 00:33:39.698812 28773 net.cpp:42] Initializing net from parameters: 
name: "overfeat"
input: "data"
input_dim: 128
input_dim: 3
input_dim: 231
input_dim: 231
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "conv1/11x11_s4"
  type: "Convolution"
  bottom: "data"
  top: "conv1/11x11_s4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/11x11_s4"
  top: "conv1/11x11_s4"
}
layer {
  name: "pool1/2x2_s2"
  type: "Pooling"
  bottom: "conv1/11x11_s4"
  top: "pool1/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2/5x5_s1"
  type: "Convolution"
  bottom: "pool1/2x2_s2"
  top: "conv2/5x5_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2/5x5_s1"
  top: "conv2/5x5_s1"
}
layer {
  name: "pool2/2x2_s2"
  type: "Pooling"
  bottom: "conv2/5x5_s1"
  top: "pool2/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/2x2_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "conv4/3x3_s1"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "pool5/2x2_s2"
  type: "Pooling"
  bottom: "conv5/3x3_s1"
  top: "pool5/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
I0417 00:33:39.698866 28773 net.cpp:340] Input 0 -> data
I0417 00:33:39.698894 28773 layer_factory.hpp:74] Creating layer conv1/11x11_s4
I0417 00:33:39.698911 28773 net.cpp:84] Creating Layer conv1/11x11_s4
I0417 00:33:39.698915 28773 net.cpp:380] conv1/11x11_s4 <- data
I0417 00:33:39.698922 28773 net.cpp:338] conv1/11x11_s4 -> conv1/11x11_s4
I0417 00:33:39.698938 28773 net.cpp:113] Setting up conv1/11x11_s4
I0417 00:33:39.699512 28773 net.cpp:120] Top shape: 128 96 56 56 (38535168)
I0417 00:33:39.699527 28773 layer_factory.hpp:74] Creating layer conv1/relu
I0417 00:33:39.699532 28773 net.cpp:84] Creating Layer conv1/relu
I0417 00:33:39.699535 28773 net.cpp:380] conv1/relu <- conv1/11x11_s4
I0417 00:33:39.699539 28773 net.cpp:327] conv1/relu -> conv1/11x11_s4 (in-place)
I0417 00:33:39.699544 28773 net.cpp:113] Setting up conv1/relu
I0417 00:33:39.699553 28773 net.cpp:120] Top shape: 128 96 56 56 (38535168)
I0417 00:33:39.699556 28773 layer_factory.hpp:74] Creating layer pool1/2x2_s2
I0417 00:33:39.699561 28773 net.cpp:84] Creating Layer pool1/2x2_s2
I0417 00:33:39.699564 28773 net.cpp:380] pool1/2x2_s2 <- conv1/11x11_s4
I0417 00:33:39.699568 28773 net.cpp:338] pool1/2x2_s2 -> pool1/2x2_s2
I0417 00:33:39.699574 28773 net.cpp:113] Setting up pool1/2x2_s2
I0417 00:33:39.699585 28773 net.cpp:120] Top shape: 128 96 28 28 (9633792)
I0417 00:33:39.699589 28773 layer_factory.hpp:74] Creating layer conv2/5x5_s1
I0417 00:33:39.699594 28773 net.cpp:84] Creating Layer conv2/5x5_s1
I0417 00:33:39.699597 28773 net.cpp:380] conv2/5x5_s1 <- pool1/2x2_s2
I0417 00:33:39.699601 28773 net.cpp:338] conv2/5x5_s1 -> conv2/5x5_s1
I0417 00:33:39.699606 28773 net.cpp:113] Setting up conv2/5x5_s1
I0417 00:33:39.703282 28773 net.cpp:120] Top shape: 128 256 24 24 (18874368)
I0417 00:33:39.703294 28773 layer_factory.hpp:74] Creating layer conv2/relu
I0417 00:33:39.703299 28773 net.cpp:84] Creating Layer conv2/relu
I0417 00:33:39.703301 28773 net.cpp:380] conv2/relu <- conv2/5x5_s1
I0417 00:33:39.703305 28773 net.cpp:327] conv2/relu -> conv2/5x5_s1 (in-place)
I0417 00:33:39.703310 28773 net.cpp:113] Setting up conv2/relu
I0417 00:33:39.703315 28773 net.cpp:120] Top shape: 128 256 24 24 (18874368)
I0417 00:33:39.703317 28773 layer_factory.hpp:74] Creating layer pool2/2x2_s2
I0417 00:33:39.703322 28773 net.cpp:84] Creating Layer pool2/2x2_s2
I0417 00:33:39.703325 28773 net.cpp:380] pool2/2x2_s2 <- conv2/5x5_s1
I0417 00:33:39.703328 28773 net.cpp:338] pool2/2x2_s2 -> pool2/2x2_s2
I0417 00:33:39.703333 28773 net.cpp:113] Setting up pool2/2x2_s2
I0417 00:33:39.703340 28773 net.cpp:120] Top shape: 128 256 12 12 (4718592)
I0417 00:33:39.703343 28773 layer_factory.hpp:74] Creating layer conv3/3x3_s1
I0417 00:33:39.703347 28773 net.cpp:84] Creating Layer conv3/3x3_s1
I0417 00:33:39.703351 28773 net.cpp:380] conv3/3x3_s1 <- pool2/2x2_s2
I0417 00:33:39.703354 28773 net.cpp:338] conv3/3x3_s1 -> conv3/3x3_s1
I0417 00:33:39.703361 28773 net.cpp:113] Setting up conv3/3x3_s1
I0417 00:33:39.710144 28773 net.cpp:120] Top shape: 128 512 12 12 (9437184)
I0417 00:33:39.710155 28773 layer_factory.hpp:74] Creating layer conv3/relu
I0417 00:33:39.710160 28773 net.cpp:84] Creating Layer conv3/relu
I0417 00:33:39.710162 28773 net.cpp:380] conv3/relu <- conv3/3x3_s1
I0417 00:33:39.710166 28773 net.cpp:327] conv3/relu -> conv3/3x3_s1 (in-place)
I0417 00:33:39.710171 28773 net.cpp:113] Setting up conv3/relu
I0417 00:33:39.710175 28773 net.cpp:120] Top shape: 128 512 12 12 (9437184)
I0417 00:33:39.710178 28773 layer_factory.hpp:74] Creating layer conv4/3x3_s1
I0417 00:33:39.710183 28773 net.cpp:84] Creating Layer conv4/3x3_s1
I0417 00:33:39.710186 28773 net.cpp:380] conv4/3x3_s1 <- conv3/3x3_s1
I0417 00:33:39.710191 28773 net.cpp:338] conv4/3x3_s1 -> conv4/3x3_s1
I0417 00:33:39.710196 28773 net.cpp:113] Setting up conv4/3x3_s1
I0417 00:33:39.735800 28773 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:33:39.735823 28773 layer_factory.hpp:74] Creating layer conv4/relu
I0417 00:33:39.735831 28773 net.cpp:84] Creating Layer conv4/relu
I0417 00:33:39.735834 28773 net.cpp:380] conv4/relu <- conv4/3x3_s1
I0417 00:33:39.735839 28773 net.cpp:327] conv4/relu -> conv4/3x3_s1 (in-place)
I0417 00:33:39.735846 28773 net.cpp:113] Setting up conv4/relu
I0417 00:33:39.735851 28773 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:33:39.735853 28773 layer_factory.hpp:74] Creating layer conv5/3x3_s1
I0417 00:33:39.735859 28773 net.cpp:84] Creating Layer conv5/3x3_s1
I0417 00:33:39.735872 28773 net.cpp:380] conv5/3x3_s1 <- conv4/3x3_s1
I0417 00:33:39.735877 28773 net.cpp:338] conv5/3x3_s1 -> conv5/3x3_s1
I0417 00:33:39.735883 28773 net.cpp:113] Setting up conv5/3x3_s1
I0417 00:33:39.787034 28773 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:33:39.787063 28773 layer_factory.hpp:74] Creating layer conv5/relu
I0417 00:33:39.787071 28773 net.cpp:84] Creating Layer conv5/relu
I0417 00:33:39.787075 28773 net.cpp:380] conv5/relu <- conv5/3x3_s1
I0417 00:33:39.787082 28773 net.cpp:327] conv5/relu -> conv5/3x3_s1 (in-place)
I0417 00:33:39.787087 28773 net.cpp:113] Setting up conv5/relu
I0417 00:33:39.787092 28773 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:33:39.787096 28773 layer_factory.hpp:74] Creating layer pool5/2x2_s2
I0417 00:33:39.787101 28773 net.cpp:84] Creating Layer pool5/2x2_s2
I0417 00:33:39.787104 28773 net.cpp:380] pool5/2x2_s2 <- conv5/3x3_s1
I0417 00:33:39.787108 28773 net.cpp:338] pool5/2x2_s2 -> pool5/2x2_s2
I0417 00:33:39.787114 28773 net.cpp:113] Setting up pool5/2x2_s2
I0417 00:33:39.787122 28773 net.cpp:120] Top shape: 128 1024 6 6 (4718592)
I0417 00:33:39.787124 28773 net.cpp:169] pool5/2x2_s2 does not need backward computation.
I0417 00:33:39.787127 28773 net.cpp:169] conv5/relu does not need backward computation.
I0417 00:33:39.787130 28773 net.cpp:169] conv5/3x3_s1 does not need backward computation.
I0417 00:33:39.787132 28773 net.cpp:169] conv4/relu does not need backward computation.
I0417 00:33:39.787135 28773 net.cpp:169] conv4/3x3_s1 does not need backward computation.
I0417 00:33:39.787137 28773 net.cpp:169] conv3/relu does not need backward computation.
I0417 00:33:39.787140 28773 net.cpp:169] conv3/3x3_s1 does not need backward computation.
I0417 00:33:39.787143 28773 net.cpp:169] pool2/2x2_s2 does not need backward computation.
I0417 00:33:39.787145 28773 net.cpp:169] conv2/relu does not need backward computation.
I0417 00:33:39.787148 28773 net.cpp:169] conv2/5x5_s1 does not need backward computation.
I0417 00:33:39.787150 28773 net.cpp:169] pool1/2x2_s2 does not need backward computation.
I0417 00:33:39.787153 28773 net.cpp:169] conv1/relu does not need backward computation.
I0417 00:33:39.787155 28773 net.cpp:169] conv1/11x11_s4 does not need backward computation.
I0417 00:33:39.787159 28773 net.cpp:205] This network produces output pool5/2x2_s2
I0417 00:33:39.787171 28773 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0417 00:33:39.787178 28773 net.cpp:217] Network initialization done.
I0417 00:33:39.787180 28773 net.cpp:218] Memory required for data: 913047552
I0417 00:33:39.787232 28773 caffe.cpp:224] Performing Forward
I0417 00:33:39.994163 28773 caffe.cpp:229] Initial loss: 0
I0417 00:33:39.994202 28773 caffe.cpp:230] Performing Backward
I0417 00:33:40.581459 28773 caffe.cpp:238] *** Benchmark begins ***
I0417 00:33:40.581480 28773 caffe.cpp:239] Testing for 10 iterations.
I0417 00:33:41.454538 28773 caffe.cpp:270] Iteration: 1 forward-backward time: 824.344 ms.
I0417 00:33:42.278208 28773 caffe.cpp:270] Iteration: 2 forward-backward time: 823.585 ms.
I0417 00:33:43.102134 28773 caffe.cpp:270] Iteration: 3 forward-backward time: 823.855 ms.
I0417 00:33:43.927109 28773 caffe.cpp:270] Iteration: 4 forward-backward time: 824.906 ms.
I0417 00:33:44.751047 28773 caffe.cpp:270] Iteration: 5 forward-backward time: 823.867 ms.
I0417 00:33:45.573222 28773 caffe.cpp:270] Iteration: 6 forward-backward time: 822.108 ms.
I0417 00:33:46.397572 28773 caffe.cpp:270] Iteration: 7 forward-backward time: 824.292 ms.
I0417 00:33:47.222241 28773 caffe.cpp:270] Iteration: 8 forward-backward time: 824.595 ms.
I0417 00:33:48.046463 28773 caffe.cpp:270] Iteration: 9 forward-backward time: 824.138 ms.
I0417 00:33:48.871106 28773 caffe.cpp:270] Iteration: 10 forward-backward time: 824.56 ms.
I0417 00:33:48.871140 28773 caffe.cpp:273] Average time per layer: 
I0417 00:33:48.871143 28773 caffe.cpp:276] conv1/11x11_s4	forward: 28.3054 ms.
I0417 00:33:48.871147 28773 caffe.cpp:279] conv1/11x11_s4	backward: 55.9995 ms.
I0417 00:33:48.871158 28773 caffe.cpp:276] conv1/relu	forward: 1.22327 ms.
I0417 00:33:48.871162 28773 caffe.cpp:279] conv1/relu	backward: 1.81158 ms.
I0417 00:33:48.871165 28773 caffe.cpp:276] pool1/2x2_s2	forward: 0.94464 ms.
I0417 00:33:48.871170 28773 caffe.cpp:279] pool1/2x2_s2	backward: 4.81986 ms.
I0417 00:33:48.871172 28773 caffe.cpp:276] conv2/5x5_s1	forward: 40.824 ms.
I0417 00:33:48.871176 28773 caffe.cpp:279] conv2/5x5_s1	backward: 66.3783 ms.
I0417 00:33:48.871178 28773 caffe.cpp:276] conv2/relu	forward: 0.599082 ms.
I0417 00:33:48.871182 28773 caffe.cpp:279] conv2/relu	backward: 0.889555 ms.
I0417 00:33:48.871186 28773 caffe.cpp:276] pool2/2x2_s2	forward: 0.471869 ms.
I0417 00:33:48.871188 28773 caffe.cpp:279] pool2/2x2_s2	backward: 2.36513 ms.
I0417 00:33:48.871191 28773 caffe.cpp:276] conv3/3x3_s1	forward: 32.2407 ms.
I0417 00:33:48.871196 28773 caffe.cpp:279] conv3/3x3_s1	backward: 32.121 ms.
I0417 00:33:48.871198 28773 caffe.cpp:276] conv3/relu	forward: 0.301165 ms.
I0417 00:33:48.871201 28773 caffe.cpp:279] conv3/relu	backward: 0.448829 ms.
I0417 00:33:48.871204 28773 caffe.cpp:276] conv4/3x3_s1	forward: 83.4528 ms.
I0417 00:33:48.871207 28773 caffe.cpp:279] conv4/3x3_s1	backward: 102.948 ms.
I0417 00:33:48.871212 28773 caffe.cpp:276] conv4/relu	forward: 0.601088 ms.
I0417 00:33:48.871214 28773 caffe.cpp:279] conv4/relu	backward: 0.893443 ms.
I0417 00:33:48.871217 28773 caffe.cpp:276] conv5/3x3_s1	forward: 164.86 ms.
I0417 00:33:48.871220 28773 caffe.cpp:279] conv5/3x3_s1	backward: 196.949 ms.
I0417 00:33:48.871224 28773 caffe.cpp:276] conv5/relu	forward: 0.603162 ms.
I0417 00:33:48.871227 28773 caffe.cpp:279] conv5/relu	backward: 0.890278 ms.
I0417 00:33:48.871230 28773 caffe.cpp:276] pool5/2x2_s2	forward: 0.491021 ms.
I0417 00:33:48.871233 28773 caffe.cpp:279] pool5/2x2_s2	backward: 2.37589 ms.
I0417 00:33:48.871244 28773 caffe.cpp:284] Average Forward pass: 355.015 ms.
I0417 00:33:48.871248 28773 caffe.cpp:286] Average Backward pass: 468.996 ms.
I0417 00:33:48.871253 28773 caffe.cpp:288] Average Forward-Backward: 824.088 ms.
I0417 00:33:48.871258 28773 caffe.cpp:290] Total Time: 8240.88 ms.
I0417 00:33:48.871261 28773 caffe.cpp:291] *** Benchmark ends ***
