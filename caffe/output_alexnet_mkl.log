I1022 01:20:29.182883  6306 caffe.cpp:301] Use CPU.
I1022 01:20:29.184303  6306 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1022 01:20:29.184325  6306 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1022 01:20:29.184396  6306 net.cpp:50] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
  }
  data_param {
    source: "/home/awesomebox/code/caffe/examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 192
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1022 01:20:29.184460  6306 layer_factory.hpp:76] Creating layer data
I1022 01:20:29.185003  6306 net.cpp:110] Creating Layer data
I1022 01:20:29.185016  6306 net.cpp:433] data -> data
I1022 01:20:29.185044  6306 net.cpp:433] data -> label
I1022 01:20:29.185130  6308 db_lmdb.cpp:23] Opened lmdb /home/awesomebox/code/caffe/examples/imagenet/ilsvrc12_train_lmdb
I1022 01:20:29.185385  6306 data_layer.cpp:45] output data size: 256,3,227,227
I1022 01:20:29.260785  6306 net.cpp:155] Setting up data
I1022 01:20:29.260833  6306 net.cpp:163] Top shape: 256 3 227 227 (39574272)
I1022 01:20:29.260838  6306 net.cpp:163] Top shape: 256 (256)
I1022 01:20:29.260846  6306 layer_factory.hpp:76] Creating layer conv1
I1022 01:20:29.260861  6306 net.cpp:110] Creating Layer conv1
I1022 01:20:29.260866  6306 net.cpp:477] conv1 <- data
I1022 01:20:29.260877  6306 net.cpp:433] conv1 -> conv1
I1022 01:20:29.260942  6306 net.cpp:155] Setting up conv1
I1022 01:20:29.260951  6306 net.cpp:163] Top shape: 256 64 55 55 (49561600)
I1022 01:20:29.260963  6306 layer_factory.hpp:76] Creating layer relu1
I1022 01:20:29.260972  6306 net.cpp:110] Creating Layer relu1
I1022 01:20:29.260974  6306 net.cpp:477] relu1 <- conv1
I1022 01:20:29.260979  6306 net.cpp:419] relu1 -> conv1 (in-place)
I1022 01:20:29.260992  6306 net.cpp:155] Setting up relu1
I1022 01:20:29.261004  6306 net.cpp:163] Top shape: 256 64 55 55 (49561600)
I1022 01:20:29.261008  6306 layer_factory.hpp:76] Creating layer pool1
I1022 01:20:29.261014  6306 net.cpp:110] Creating Layer pool1
I1022 01:20:29.261018  6306 net.cpp:477] pool1 <- conv1
I1022 01:20:29.261023  6306 net.cpp:433] pool1 -> pool1
I1022 01:20:29.261039  6306 net.cpp:155] Setting up pool1
I1022 01:20:29.261042  6306 net.cpp:163] Top shape: 256 64 27 27 (11943936)
I1022 01:20:29.261046  6306 layer_factory.hpp:76] Creating layer conv2
I1022 01:20:29.261052  6306 net.cpp:110] Creating Layer conv2
I1022 01:20:29.261056  6306 net.cpp:477] conv2 <- pool1
I1022 01:20:29.261060  6306 net.cpp:433] conv2 -> conv2
I1022 01:20:29.261291  6306 net.cpp:155] Setting up conv2
I1022 01:20:29.261299  6306 net.cpp:163] Top shape: 256 192 27 27 (35831808)
I1022 01:20:29.261307  6306 layer_factory.hpp:76] Creating layer relu2
I1022 01:20:29.261313  6306 net.cpp:110] Creating Layer relu2
I1022 01:20:29.261317  6306 net.cpp:477] relu2 <- conv2
I1022 01:20:29.261322  6306 net.cpp:419] relu2 -> conv2 (in-place)
I1022 01:20:29.261327  6306 net.cpp:155] Setting up relu2
I1022 01:20:29.261330  6306 net.cpp:163] Top shape: 256 192 27 27 (35831808)
I1022 01:20:29.261333  6306 layer_factory.hpp:76] Creating layer pool2
I1022 01:20:29.261338  6306 net.cpp:110] Creating Layer pool2
I1022 01:20:29.261342  6306 net.cpp:477] pool2 <- conv2
I1022 01:20:29.261345  6306 net.cpp:433] pool2 -> pool2
I1022 01:20:29.261353  6306 net.cpp:155] Setting up pool2
I1022 01:20:29.261356  6306 net.cpp:163] Top shape: 256 192 13 13 (8306688)
I1022 01:20:29.261359  6306 layer_factory.hpp:76] Creating layer conv3
I1022 01:20:29.261365  6306 net.cpp:110] Creating Layer conv3
I1022 01:20:29.261368  6306 net.cpp:477] conv3 <- pool2
I1022 01:20:29.261373  6306 net.cpp:433] conv3 -> conv3
I1022 01:20:29.261997  6306 net.cpp:155] Setting up conv3
I1022 01:20:29.262007  6306 net.cpp:163] Top shape: 256 384 13 13 (16613376)
I1022 01:20:29.262017  6306 layer_factory.hpp:76] Creating layer relu3
I1022 01:20:29.262022  6306 net.cpp:110] Creating Layer relu3
I1022 01:20:29.262027  6306 net.cpp:477] relu3 <- conv3
I1022 01:20:29.262030  6306 net.cpp:419] relu3 -> conv3 (in-place)
I1022 01:20:29.262037  6306 net.cpp:155] Setting up relu3
I1022 01:20:29.262040  6306 net.cpp:163] Top shape: 256 384 13 13 (16613376)
I1022 01:20:29.262043  6306 layer_factory.hpp:76] Creating layer conv4
I1022 01:20:29.262049  6306 net.cpp:110] Creating Layer conv4
I1022 01:20:29.262053  6306 net.cpp:477] conv4 <- conv3
I1022 01:20:29.262056  6306 net.cpp:433] conv4 -> conv4
I1022 01:20:29.263345  6306 net.cpp:155] Setting up conv4
I1022 01:20:29.263360  6306 net.cpp:163] Top shape: 256 256 13 13 (11075584)
I1022 01:20:29.263365  6306 layer_factory.hpp:76] Creating layer relu4
I1022 01:20:29.263371  6306 net.cpp:110] Creating Layer relu4
I1022 01:20:29.263375  6306 net.cpp:477] relu4 <- conv4
I1022 01:20:29.263380  6306 net.cpp:419] relu4 -> conv4 (in-place)
I1022 01:20:29.263386  6306 net.cpp:155] Setting up relu4
I1022 01:20:29.263389  6306 net.cpp:163] Top shape: 256 256 13 13 (11075584)
I1022 01:20:29.263392  6306 layer_factory.hpp:76] Creating layer conv5
I1022 01:20:29.263397  6306 net.cpp:110] Creating Layer conv5
I1022 01:20:29.263401  6306 net.cpp:477] conv5 <- conv4
I1022 01:20:29.263406  6306 net.cpp:433] conv5 -> conv5
I1022 01:20:29.264250  6306 net.cpp:155] Setting up conv5
I1022 01:20:29.264262  6306 net.cpp:163] Top shape: 256 256 13 13 (11075584)
I1022 01:20:29.264271  6306 layer_factory.hpp:76] Creating layer relu5
I1022 01:20:29.264277  6306 net.cpp:110] Creating Layer relu5
I1022 01:20:29.264281  6306 net.cpp:477] relu5 <- conv5
I1022 01:20:29.264286  6306 net.cpp:419] relu5 -> conv5 (in-place)
I1022 01:20:29.264291  6306 net.cpp:155] Setting up relu5
I1022 01:20:29.264294  6306 net.cpp:163] Top shape: 256 256 13 13 (11075584)
I1022 01:20:29.264297  6306 layer_factory.hpp:76] Creating layer pool5
I1022 01:20:29.264302  6306 net.cpp:110] Creating Layer pool5
I1022 01:20:29.264305  6306 net.cpp:477] pool5 <- conv5
I1022 01:20:29.264319  6306 net.cpp:433] pool5 -> pool5
I1022 01:20:29.264328  6306 net.cpp:155] Setting up pool5
I1022 01:20:29.264333  6306 net.cpp:163] Top shape: 256 256 6 6 (2359296)
I1022 01:20:29.264335  6306 layer_factory.hpp:76] Creating layer fc6
I1022 01:20:29.264340  6306 net.cpp:110] Creating Layer fc6
I1022 01:20:29.264343  6306 net.cpp:477] fc6 <- pool5
I1022 01:20:29.264349  6306 net.cpp:433] fc6 -> fc6
I1022 01:20:29.299417  6306 net.cpp:155] Setting up fc6
I1022 01:20:29.299444  6306 net.cpp:163] Top shape: 256 4096 (1048576)
I1022 01:20:29.299453  6306 layer_factory.hpp:76] Creating layer fc7
I1022 01:20:29.299463  6306 net.cpp:110] Creating Layer fc7
I1022 01:20:29.299468  6306 net.cpp:477] fc7 <- fc6
I1022 01:20:29.299475  6306 net.cpp:433] fc7 -> fc7
I1022 01:20:29.314847  6306 net.cpp:155] Setting up fc7
I1022 01:20:29.314873  6306 net.cpp:163] Top shape: 256 4096 (1048576)
I1022 01:20:29.314882  6306 layer_factory.hpp:76] Creating layer fc8
I1022 01:20:29.314893  6306 net.cpp:110] Creating Layer fc8
I1022 01:20:29.314898  6306 net.cpp:477] fc8 <- fc7
I1022 01:20:29.314904  6306 net.cpp:433] fc8 -> fc8
I1022 01:20:29.318774  6306 net.cpp:155] Setting up fc8
I1022 01:20:29.318799  6306 net.cpp:163] Top shape: 256 1000 (256000)
I1022 01:20:29.318809  6306 layer_factory.hpp:76] Creating layer loss
I1022 01:20:29.318816  6306 net.cpp:110] Creating Layer loss
I1022 01:20:29.318821  6306 net.cpp:477] loss <- fc8
I1022 01:20:29.318826  6306 net.cpp:477] loss <- label
I1022 01:20:29.318832  6306 net.cpp:433] loss -> loss
I1022 01:20:29.318843  6306 layer_factory.hpp:76] Creating layer loss
I1022 01:20:29.319195  6306 net.cpp:155] Setting up loss
I1022 01:20:29.319205  6306 net.cpp:163] Top shape: (1)
I1022 01:20:29.319210  6306 net.cpp:168]     with loss weight 1
I1022 01:20:29.319226  6306 net.cpp:236] loss needs backward computation.
I1022 01:20:29.319229  6306 net.cpp:236] fc8 needs backward computation.
I1022 01:20:29.319232  6306 net.cpp:236] fc7 needs backward computation.
I1022 01:20:29.319236  6306 net.cpp:236] fc6 needs backward computation.
I1022 01:20:29.319238  6306 net.cpp:236] pool5 needs backward computation.
I1022 01:20:29.319242  6306 net.cpp:236] relu5 needs backward computation.
I1022 01:20:29.319246  6306 net.cpp:236] conv5 needs backward computation.
I1022 01:20:29.319248  6306 net.cpp:236] relu4 needs backward computation.
I1022 01:20:29.319252  6306 net.cpp:236] conv4 needs backward computation.
I1022 01:20:29.319254  6306 net.cpp:236] relu3 needs backward computation.
I1022 01:20:29.319257  6306 net.cpp:236] conv3 needs backward computation.
I1022 01:20:29.319260  6306 net.cpp:236] pool2 needs backward computation.
I1022 01:20:29.319264  6306 net.cpp:236] relu2 needs backward computation.
I1022 01:20:29.319267  6306 net.cpp:236] conv2 needs backward computation.
I1022 01:20:29.319270  6306 net.cpp:236] pool1 needs backward computation.
I1022 01:20:29.319273  6306 net.cpp:236] relu1 needs backward computation.
I1022 01:20:29.319277  6306 net.cpp:236] conv1 needs backward computation.
I1022 01:20:29.319279  6306 net.cpp:240] data does not need backward computation.
I1022 01:20:29.319283  6306 net.cpp:283] This network produces output loss
I1022 01:20:29.319293  6306 net.cpp:297] Network initialization done.
I1022 01:20:29.319295  6306 net.cpp:298] Memory required for data: 1251414020
I1022 01:20:29.319366  6306 caffe.cpp:309] Performing Forward
I1022 01:20:29.319375  6306 blocking_queue.cpp:50] Data layer prefetch queue empty
I1022 01:20:33.031155  6306 caffe.cpp:314] Initial loss: 6.90774
I1022 01:20:33.031196  6306 caffe.cpp:315] Performing Backward
I1022 01:20:39.054239  6306 caffe.cpp:323] *** Benchmark begins ***
I1022 01:20:39.054277  6306 caffe.cpp:324] Testing for 10 iterations.
I1022 01:20:48.024272  6306 caffe.cpp:352] Iteration: 1 forward-backward time: 8969 ms.
I1022 01:20:53.495117  6306 caffe.cpp:352] Iteration: 2 forward-backward time: 5470 ms.
I1022 01:20:58.638541  6306 caffe.cpp:352] Iteration: 3 forward-backward time: 5143 ms.
I1022 01:21:03.803921  6306 caffe.cpp:352] Iteration: 4 forward-backward time: 5165 ms.
I1022 01:21:08.977149  6306 caffe.cpp:352] Iteration: 5 forward-backward time: 5173 ms.
I1022 01:21:14.142892  6306 caffe.cpp:352] Iteration: 6 forward-backward time: 5165 ms.
I1022 01:21:19.311138  6306 caffe.cpp:352] Iteration: 7 forward-backward time: 5168 ms.
I1022 01:21:24.459045  6306 caffe.cpp:352] Iteration: 8 forward-backward time: 5147 ms.
I1022 01:21:29.613479  6306 caffe.cpp:352] Iteration: 9 forward-backward time: 5154 ms.
I1022 01:21:34.775128  6306 caffe.cpp:352] Iteration: 10 forward-backward time: 5161 ms.
I1022 01:21:34.775166  6306 caffe.cpp:355] Average time per layer: 
I1022 01:21:34.775173  6306 caffe.cpp:358]       data	forward: 21.389 ms.
I1022 01:21:34.775179  6306 caffe.cpp:361]       data	backward: 0.0007 ms.
I1022 01:21:34.775182  6306 caffe.cpp:358]      conv1	forward: 357.069 ms.
I1022 01:21:34.775187  6306 caffe.cpp:361]      conv1	backward: 330.767 ms.
I1022 01:21:34.775190  6306 caffe.cpp:358]      relu1	forward: 47.1887 ms.
I1022 01:21:34.775193  6306 caffe.cpp:361]      relu1	backward: 57.7991 ms.
I1022 01:21:34.775197  6306 caffe.cpp:358]      pool1	forward: 216.237 ms.
I1022 01:21:34.775200  6306 caffe.cpp:361]      pool1	backward: 92.3998 ms.
I1022 01:21:34.775204  6306 caffe.cpp:358]      conv2	forward: 533.456 ms.
I1022 01:21:34.775207  6306 caffe.cpp:361]      conv2	backward: 1007.32 ms.
I1022 01:21:34.775210  6306 caffe.cpp:358]      relu2	forward: 32.5319 ms.
I1022 01:21:34.775214  6306 caffe.cpp:361]      relu2	backward: 41.8427 ms.
I1022 01:21:34.775218  6306 caffe.cpp:358]      pool2	forward: 138.228 ms.
I1022 01:21:34.775221  6306 caffe.cpp:361]      pool2	backward: 71.5279 ms.
I1022 01:21:34.775224  6306 caffe.cpp:358]      conv3	forward: 207.55 ms.
I1022 01:21:34.775228  6306 caffe.cpp:361]      conv3	backward: 415.731 ms.
I1022 01:21:34.775231  6306 caffe.cpp:358]      relu3	forward: 15.1693 ms.
I1022 01:21:34.775234  6306 caffe.cpp:361]      relu3	backward: 19.5894 ms.
I1022 01:21:34.775238  6306 caffe.cpp:358]      conv4	forward: 321.758 ms.
I1022 01:21:34.775241  6306 caffe.cpp:361]      conv4	backward: 658.584 ms.
I1022 01:21:34.775245  6306 caffe.cpp:358]      relu4	forward: 10.159 ms.
I1022 01:21:34.775249  6306 caffe.cpp:361]      relu4	backward: 13.0562 ms.
I1022 01:21:34.775251  6306 caffe.cpp:358]      conv5	forward: 218.284 ms.
I1022 01:21:34.775255  6306 caffe.cpp:361]      conv5	backward: 435.634 ms.
I1022 01:21:34.775259  6306 caffe.cpp:358]      relu5	forward: 10.1855 ms.
I1022 01:21:34.775262  6306 caffe.cpp:361]      relu5	backward: 12.9499 ms.
I1022 01:21:34.775265  6306 caffe.cpp:358]      pool5	forward: 53.2655 ms.
I1022 01:21:34.775269  6306 caffe.cpp:361]      pool5	backward: 31.1371 ms.
I1022 01:21:34.775272  6306 caffe.cpp:358]        fc6	forward: 42.6512 ms.
I1022 01:21:34.775275  6306 caffe.cpp:361]        fc6	backward: 77.2451 ms.
I1022 01:21:34.775279  6306 caffe.cpp:358]        fc7	forward: 20.1991 ms.
I1022 01:21:34.775282  6306 caffe.cpp:361]        fc7	backward: 37.3001 ms.
I1022 01:21:34.775285  6306 caffe.cpp:358]        fc8	forward: 5.7591 ms.
I1022 01:21:34.775290  6306 caffe.cpp:361]        fc8	backward: 9.0703 ms.
I1022 01:21:34.775292  6306 caffe.cpp:358]       loss	forward: 8.7884 ms.
I1022 01:21:34.775295  6306 caffe.cpp:361]       loss	backward: 0.1575 ms.
I1022 01:21:34.775301  6306 caffe.cpp:366] Average Forward pass: 2259.9 ms.
I1022 01:21:34.775305  6306 caffe.cpp:368] Average Backward pass: 3312.14 ms.
I1022 01:21:34.775308  6306 caffe.cpp:370] Average Forward-Backward: 5572.1 ms.
I1022 01:21:34.775311  6306 caffe.cpp:372] Total Time: 55721 ms.
I1022 01:21:34.775315  6306 caffe.cpp:373] *** Benchmark ends ***
