I0417 00:12:38.946389 28384 caffe.cpp:212] Use GPU with device ID 0
E0417 00:12:39.144912 28384 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/overfeat.prototxt
I0417 00:12:39.144981 28384 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0417 00:12:39.145122 28384 net.cpp:42] Initializing net from parameters: 
name: "overfeat"
input: "data"
input_dim: 128
input_dim: 3
input_dim: 231
input_dim: 231
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "conv1/11x11_s4"
  type: "Convolution"
  bottom: "data"
  top: "conv1/11x11_s4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/11x11_s4"
  top: "conv1/11x11_s4"
}
layer {
  name: "pool1/2x2_s2"
  type: "Pooling"
  bottom: "conv1/11x11_s4"
  top: "pool1/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2/5x5_s1"
  type: "Convolution"
  bottom: "pool1/2x2_s2"
  top: "conv2/5x5_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2/5x5_s1"
  top: "conv2/5x5_s1"
}
layer {
  name: "pool2/2x2_s2"
  type: "Pooling"
  bottom: "conv2/5x5_s1"
  top: "pool2/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/2x2_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "conv4/3x3_s1"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "pool5/2x2_s2"
  type: "Pooling"
  bottom: "conv5/3x3_s1"
  top: "pool5/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5/2x2_s2"
  top: "fc6-conv"
  convolution_param {
    num_output: 3072
    kernel_size: 6
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "fc8-conv"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-conv"
  convolution_param {
    num_output: 1000
    kernel_size: 1
  }
}
I0417 00:12:39.145175 28384 net.cpp:340] Input 0 -> data
I0417 00:12:39.145215 28384 layer_factory.hpp:74] Creating layer conv1/11x11_s4
I0417 00:12:39.145231 28384 net.cpp:84] Creating Layer conv1/11x11_s4
I0417 00:12:39.145236 28384 net.cpp:380] conv1/11x11_s4 <- data
I0417 00:12:39.145242 28384 net.cpp:338] conv1/11x11_s4 -> conv1/11x11_s4
I0417 00:12:39.145252 28384 net.cpp:113] Setting up conv1/11x11_s4
I0417 00:12:39.145815 28384 net.cpp:120] Top shape: 128 96 56 56 (38535168)
I0417 00:12:39.145828 28384 layer_factory.hpp:74] Creating layer conv1/relu
I0417 00:12:39.145835 28384 net.cpp:84] Creating Layer conv1/relu
I0417 00:12:39.145838 28384 net.cpp:380] conv1/relu <- conv1/11x11_s4
I0417 00:12:39.145843 28384 net.cpp:327] conv1/relu -> conv1/11x11_s4 (in-place)
I0417 00:12:39.145848 28384 net.cpp:113] Setting up conv1/relu
I0417 00:12:39.145856 28384 net.cpp:120] Top shape: 128 96 56 56 (38535168)
I0417 00:12:39.145859 28384 layer_factory.hpp:74] Creating layer pool1/2x2_s2
I0417 00:12:39.145864 28384 net.cpp:84] Creating Layer pool1/2x2_s2
I0417 00:12:39.145867 28384 net.cpp:380] pool1/2x2_s2 <- conv1/11x11_s4
I0417 00:12:39.145871 28384 net.cpp:338] pool1/2x2_s2 -> pool1/2x2_s2
I0417 00:12:39.145876 28384 net.cpp:113] Setting up pool1/2x2_s2
I0417 00:12:39.145887 28384 net.cpp:120] Top shape: 128 96 28 28 (9633792)
I0417 00:12:39.145890 28384 layer_factory.hpp:74] Creating layer conv2/5x5_s1
I0417 00:12:39.145895 28384 net.cpp:84] Creating Layer conv2/5x5_s1
I0417 00:12:39.145898 28384 net.cpp:380] conv2/5x5_s1 <- pool1/2x2_s2
I0417 00:12:39.145902 28384 net.cpp:338] conv2/5x5_s1 -> conv2/5x5_s1
I0417 00:12:39.145908 28384 net.cpp:113] Setting up conv2/5x5_s1
I0417 00:12:39.149592 28384 net.cpp:120] Top shape: 128 256 24 24 (18874368)
I0417 00:12:39.149605 28384 layer_factory.hpp:74] Creating layer conv2/relu
I0417 00:12:39.149610 28384 net.cpp:84] Creating Layer conv2/relu
I0417 00:12:39.149613 28384 net.cpp:380] conv2/relu <- conv2/5x5_s1
I0417 00:12:39.149618 28384 net.cpp:327] conv2/relu -> conv2/5x5_s1 (in-place)
I0417 00:12:39.149622 28384 net.cpp:113] Setting up conv2/relu
I0417 00:12:39.149626 28384 net.cpp:120] Top shape: 128 256 24 24 (18874368)
I0417 00:12:39.149629 28384 layer_factory.hpp:74] Creating layer pool2/2x2_s2
I0417 00:12:39.149633 28384 net.cpp:84] Creating Layer pool2/2x2_s2
I0417 00:12:39.149636 28384 net.cpp:380] pool2/2x2_s2 <- conv2/5x5_s1
I0417 00:12:39.149641 28384 net.cpp:338] pool2/2x2_s2 -> pool2/2x2_s2
I0417 00:12:39.149646 28384 net.cpp:113] Setting up pool2/2x2_s2
I0417 00:12:39.149652 28384 net.cpp:120] Top shape: 128 256 12 12 (4718592)
I0417 00:12:39.149654 28384 layer_factory.hpp:74] Creating layer conv3/3x3_s1
I0417 00:12:39.149659 28384 net.cpp:84] Creating Layer conv3/3x3_s1
I0417 00:12:39.149662 28384 net.cpp:380] conv3/3x3_s1 <- pool2/2x2_s2
I0417 00:12:39.149667 28384 net.cpp:338] conv3/3x3_s1 -> conv3/3x3_s1
I0417 00:12:39.149672 28384 net.cpp:113] Setting up conv3/3x3_s1
I0417 00:12:39.156155 28384 net.cpp:120] Top shape: 128 512 12 12 (9437184)
I0417 00:12:39.156167 28384 layer_factory.hpp:74] Creating layer conv3/relu
I0417 00:12:39.156172 28384 net.cpp:84] Creating Layer conv3/relu
I0417 00:12:39.156175 28384 net.cpp:380] conv3/relu <- conv3/3x3_s1
I0417 00:12:39.156179 28384 net.cpp:327] conv3/relu -> conv3/3x3_s1 (in-place)
I0417 00:12:39.156184 28384 net.cpp:113] Setting up conv3/relu
I0417 00:12:39.156188 28384 net.cpp:120] Top shape: 128 512 12 12 (9437184)
I0417 00:12:39.156191 28384 layer_factory.hpp:74] Creating layer conv4/3x3_s1
I0417 00:12:39.156196 28384 net.cpp:84] Creating Layer conv4/3x3_s1
I0417 00:12:39.156199 28384 net.cpp:380] conv4/3x3_s1 <- conv3/3x3_s1
I0417 00:12:39.156203 28384 net.cpp:338] conv4/3x3_s1 -> conv4/3x3_s1
I0417 00:12:39.156209 28384 net.cpp:113] Setting up conv4/3x3_s1
I0417 00:12:39.182062 28384 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:12:39.182088 28384 layer_factory.hpp:74] Creating layer conv4/relu
I0417 00:12:39.182097 28384 net.cpp:84] Creating Layer conv4/relu
I0417 00:12:39.182101 28384 net.cpp:380] conv4/relu <- conv4/3x3_s1
I0417 00:12:39.182108 28384 net.cpp:327] conv4/relu -> conv4/3x3_s1 (in-place)
I0417 00:12:39.182122 28384 net.cpp:113] Setting up conv4/relu
I0417 00:12:39.182127 28384 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:12:39.182131 28384 layer_factory.hpp:74] Creating layer conv5/3x3_s1
I0417 00:12:39.182137 28384 net.cpp:84] Creating Layer conv5/3x3_s1
I0417 00:12:39.182140 28384 net.cpp:380] conv5/3x3_s1 <- conv4/3x3_s1
I0417 00:12:39.182147 28384 net.cpp:338] conv5/3x3_s1 -> conv5/3x3_s1
I0417 00:12:39.182153 28384 net.cpp:113] Setting up conv5/3x3_s1
I0417 00:12:39.233273 28384 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:12:39.233304 28384 layer_factory.hpp:74] Creating layer conv5/relu
I0417 00:12:39.233314 28384 net.cpp:84] Creating Layer conv5/relu
I0417 00:12:39.233317 28384 net.cpp:380] conv5/relu <- conv5/3x3_s1
I0417 00:12:39.233322 28384 net.cpp:327] conv5/relu -> conv5/3x3_s1 (in-place)
I0417 00:12:39.233328 28384 net.cpp:113] Setting up conv5/relu
I0417 00:12:39.233333 28384 net.cpp:120] Top shape: 128 1024 12 12 (18874368)
I0417 00:12:39.233336 28384 layer_factory.hpp:74] Creating layer pool5/2x2_s2
I0417 00:12:39.233345 28384 net.cpp:84] Creating Layer pool5/2x2_s2
I0417 00:12:39.233348 28384 net.cpp:380] pool5/2x2_s2 <- conv5/3x3_s1
I0417 00:12:39.233352 28384 net.cpp:338] pool5/2x2_s2 -> pool5/2x2_s2
I0417 00:12:39.233360 28384 net.cpp:113] Setting up pool5/2x2_s2
I0417 00:12:39.233366 28384 net.cpp:120] Top shape: 128 1024 6 6 (4718592)
I0417 00:12:39.233369 28384 layer_factory.hpp:74] Creating layer fc6-conv
I0417 00:12:39.233374 28384 net.cpp:84] Creating Layer fc6-conv
I0417 00:12:39.233377 28384 net.cpp:380] fc6-conv <- pool5/2x2_s2
I0417 00:12:39.233382 28384 net.cpp:338] fc6-conv -> fc6-conv
I0417 00:12:39.233387 28384 net.cpp:113] Setting up fc6-conv
I0417 00:12:40.799435 28384 net.cpp:120] Top shape: 128 3072 1 1 (393216)
I0417 00:12:40.799466 28384 layer_factory.hpp:74] Creating layer fc7-conv
I0417 00:12:40.799476 28384 net.cpp:84] Creating Layer fc7-conv
I0417 00:12:40.799480 28384 net.cpp:380] fc7-conv <- fc6-conv
I0417 00:12:40.799485 28384 net.cpp:338] fc7-conv -> fc7-conv
I0417 00:12:40.799494 28384 net.cpp:113] Setting up fc7-conv
I0417 00:12:40.979598 28384 net.cpp:120] Top shape: 128 4096 1 1 (524288)
I0417 00:12:40.979629 28384 layer_factory.hpp:74] Creating layer fc8-conv
I0417 00:12:40.979637 28384 net.cpp:84] Creating Layer fc8-conv
I0417 00:12:40.979641 28384 net.cpp:380] fc8-conv <- fc7-conv
I0417 00:12:40.979648 28384 net.cpp:338] fc8-conv -> fc8-conv
I0417 00:12:40.979657 28384 net.cpp:113] Setting up fc8-conv
I0417 00:12:41.035974 28384 net.cpp:120] Top shape: 128 1000 1 1 (128000)
I0417 00:12:41.035998 28384 net.cpp:169] fc8-conv does not need backward computation.
I0417 00:12:41.036002 28384 net.cpp:169] fc7-conv does not need backward computation.
I0417 00:12:41.036005 28384 net.cpp:169] fc6-conv does not need backward computation.
I0417 00:12:41.036008 28384 net.cpp:169] pool5/2x2_s2 does not need backward computation.
I0417 00:12:41.036011 28384 net.cpp:169] conv5/relu does not need backward computation.
I0417 00:12:41.036015 28384 net.cpp:169] conv5/3x3_s1 does not need backward computation.
I0417 00:12:41.036016 28384 net.cpp:169] conv4/relu does not need backward computation.
I0417 00:12:41.036020 28384 net.cpp:169] conv4/3x3_s1 does not need backward computation.
I0417 00:12:41.036022 28384 net.cpp:169] conv3/relu does not need backward computation.
I0417 00:12:41.036025 28384 net.cpp:169] conv3/3x3_s1 does not need backward computation.
I0417 00:12:41.036027 28384 net.cpp:169] pool2/2x2_s2 does not need backward computation.
I0417 00:12:41.036031 28384 net.cpp:169] conv2/relu does not need backward computation.
I0417 00:12:41.036032 28384 net.cpp:169] conv2/5x5_s1 does not need backward computation.
I0417 00:12:41.036036 28384 net.cpp:169] pool1/2x2_s2 does not need backward computation.
I0417 00:12:41.036037 28384 net.cpp:169] conv1/relu does not need backward computation.
I0417 00:12:41.036041 28384 net.cpp:169] conv1/11x11_s4 does not need backward computation.
I0417 00:12:41.036053 28384 net.cpp:205] This network produces output fc8-conv
I0417 00:12:41.036069 28384 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0417 00:12:41.036077 28384 net.cpp:217] Network initialization done.
I0417 00:12:41.036079 28384 net.cpp:218] Memory required for data: 917229568
I0417 00:12:41.036139 28384 caffe.cpp:224] Performing Forward
I0417 00:12:42.063928 28384 caffe.cpp:229] Initial loss: 0
I0417 00:12:42.063968 28384 caffe.cpp:230] Performing Backward
I0417 00:12:43.591097 28384 caffe.cpp:238] *** Benchmark begins ***
I0417 00:12:43.591111 28384 caffe.cpp:239] Testing for 10 iterations.
I0417 00:12:46.172008 28384 caffe.cpp:270] Iteration: 1 forward-backward time: 2533.47 ms.
I0417 00:12:48.703934 28384 caffe.cpp:270] Iteration: 2 forward-backward time: 2531.83 ms.
I0417 00:12:51.237463 28384 caffe.cpp:270] Iteration: 3 forward-backward time: 2533.44 ms.
I0417 00:12:53.769750 28384 caffe.cpp:270] Iteration: 4 forward-backward time: 2532.2 ms.
I0417 00:12:56.301800 28384 caffe.cpp:270] Iteration: 5 forward-backward time: 2531.96 ms.
I0417 00:12:58.837112 28384 caffe.cpp:270] Iteration: 6 forward-backward time: 2535.22 ms.
I0417 00:13:01.370363 28384 caffe.cpp:270] Iteration: 7 forward-backward time: 2533.15 ms.
I0417 00:13:03.905298 28384 caffe.cpp:270] Iteration: 8 forward-backward time: 2534.83 ms.
I0417 00:13:06.443753 28384 caffe.cpp:270] Iteration: 9 forward-backward time: 2538.36 ms.
I0417 00:13:09.002398 28384 caffe.cpp:270] Iteration: 10 forward-backward time: 2558.55 ms.
I0417 00:13:09.002418 28384 caffe.cpp:273] Average time per layer: 
I0417 00:13:09.002421 28384 caffe.cpp:276] conv1/11x11_s4	forward: 27.9482 ms.
I0417 00:13:09.002426 28384 caffe.cpp:279] conv1/11x11_s4	backward: 54.8106 ms.
I0417 00:13:09.002430 28384 caffe.cpp:276] conv1/relu	forward: 1.22327 ms.
I0417 00:13:09.002434 28384 caffe.cpp:279] conv1/relu	backward: 1.81259 ms.
I0417 00:13:09.002436 28384 caffe.cpp:276] pool1/2x2_s2	forward: 0.94129 ms.
I0417 00:13:09.002440 28384 caffe.cpp:279] pool1/2x2_s2	backward: 4.75915 ms.
I0417 00:13:09.002444 28384 caffe.cpp:276] conv2/5x5_s1	forward: 40.4846 ms.
I0417 00:13:09.002446 28384 caffe.cpp:279] conv2/5x5_s1	backward: 65.4555 ms.
I0417 00:13:09.002449 28384 caffe.cpp:276] conv2/relu	forward: 0.59967 ms.
I0417 00:13:09.002454 28384 caffe.cpp:279] conv2/relu	backward: 0.891712 ms.
I0417 00:13:09.002456 28384 caffe.cpp:276] pool2/2x2_s2	forward: 0.470963 ms.
I0417 00:13:09.002460 28384 caffe.cpp:279] pool2/2x2_s2	backward: 2.33738 ms.
I0417 00:13:09.002462 28384 caffe.cpp:276] conv3/3x3_s1	forward: 31.9045 ms.
I0417 00:13:09.002466 28384 caffe.cpp:279] conv3/3x3_s1	backward: 31.8685 ms.
I0417 00:13:09.002470 28384 caffe.cpp:276] conv3/relu	forward: 0.302589 ms.
I0417 00:13:09.002472 28384 caffe.cpp:279] conv3/relu	backward: 0.446272 ms.
I0417 00:13:09.002475 28384 caffe.cpp:276] conv4/3x3_s1	forward: 83.0414 ms.
I0417 00:13:09.002480 28384 caffe.cpp:279] conv4/3x3_s1	backward: 101.762 ms.
I0417 00:13:09.002482 28384 caffe.cpp:276] conv4/relu	forward: 0.599654 ms.
I0417 00:13:09.002485 28384 caffe.cpp:279] conv4/relu	backward: 0.887738 ms.
I0417 00:13:09.002488 28384 caffe.cpp:276] conv5/3x3_s1	forward: 164.436 ms.
I0417 00:13:09.002492 28384 caffe.cpp:279] conv5/3x3_s1	backward: 194.939 ms.
I0417 00:13:09.002496 28384 caffe.cpp:276] conv5/relu	forward: 0.60129 ms.
I0417 00:13:09.002499 28384 caffe.cpp:279] conv5/relu	backward: 0.891808 ms.
I0417 00:13:09.002502 28384 caffe.cpp:276] pool5/2x2_s2	forward: 0.488166 ms.
I0417 00:13:09.002506 28384 caffe.cpp:279] pool5/2x2_s2	backward: 2.34702 ms.
I0417 00:13:09.002508 28384 caffe.cpp:276]   fc6-conv	forward: 552.679 ms.
I0417 00:13:09.002512 28384 caffe.cpp:279]   fc6-conv	backward: 941.188 ms.
I0417 00:13:09.002516 28384 caffe.cpp:276]   fc7-conv	forward: 60.4307 ms.
I0417 00:13:09.002519 28384 caffe.cpp:279]   fc7-conv	backward: 105.503 ms.
I0417 00:13:09.002522 28384 caffe.cpp:276]   fc8-conv	forward: 22.6061 ms.
I0417 00:13:09.002526 28384 caffe.cpp:279]   fc8-conv	backward: 37.3689 ms.
I0417 00:13:09.002537 28384 caffe.cpp:284] Average Forward pass: 988.885 ms.
I0417 00:13:09.002549 28384 caffe.cpp:286] Average Backward pass: 1547.4 ms.
I0417 00:13:09.002555 28384 caffe.cpp:288] Average Forward-Backward: 2536.35 ms.
I0417 00:13:09.002560 28384 caffe.cpp:290] Total Time: 25363.5 ms.
I0417 00:13:09.002564 28384 caffe.cpp:291] *** Benchmark ends ***
