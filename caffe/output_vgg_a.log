I0413 19:14:43.140399 11754 caffe.cpp:212] Use GPU with device ID 0
E0413 19:14:43.339568 11754 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/vgg_a.prototxt
I0413 19:14:43.339654 11754 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0413 19:14:43.339841 11754 net.cpp:42] Initializing net from parameters: 
name: "vgg_a"
input: "data"
input_dim: 128
input_dim: 3
input_dim: 224
input_dim: 224
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "pool1/2x2_s2"
  type: "Pooling"
  bottom: "conv1/3x3_s1"
  top: "pool1/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2/3x3_s1"
  type: "Convolution"
  bottom: "pool1/2x2_s2"
  top: "conv2/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2/3x3_s1"
  top: "conv2/3x3_s1"
}
layer {
  name: "pool2/2x2_s2"
  type: "Pooling"
  bottom: "conv2/3x3_s1"
  top: "pool2/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/2x2_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "pool3/2x2_s2"
  type: "Pooling"
  bottom: "conv4/3x3_s1"
  top: "pool3/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "pool3/2x2_s2"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "conv6/3x3_s1"
  type: "Convolution"
  bottom: "conv5/3x3_s1"
  top: "conv6/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6/3x3_s1"
  top: "conv6/3x3_s1"
}
layer {
  name: "pool4/2x2_s2"
  type: "Pooling"
  bottom: "conv6/3x3_s1"
  top: "pool4/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv7/3x3_s1"
  type: "Convolution"
  bottom: "pool4/2x2_s2"
  top: "conv7/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7/3x3_s1"
  top: "conv7/3x3_s1"
}
layer {
  name: "conv8/3x3_s1"
  type: "Convolution"
  bottom: "conv7/3x3_s1"
  top: "conv8/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8/3x3_s1"
  top: "conv8/3x3_s1"
}
layer {
  name: "pool5/2x2_s2"
  type: "Pooling"
  bottom: "conv8/3x3_s1"
  top: "pool5/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5/2x2_s2"
  top: "fc6-conv"
  convolution_param {
    num_output: 4096
    kernel_size: 7
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "fc8-conv"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8"
  convolution_param {
    num_output: 1000
    kernel_size: 1
  }
}
I0413 19:14:43.339918 11754 net.cpp:340] Input 0 -> data
I0413 19:14:43.339951 11754 layer_factory.hpp:74] Creating layer conv1/3x3_s1
I0413 19:14:43.339967 11754 net.cpp:84] Creating Layer conv1/3x3_s1
I0413 19:14:43.339970 11754 net.cpp:380] conv1/3x3_s1 <- data
I0413 19:14:43.339977 11754 net.cpp:338] conv1/3x3_s1 -> conv1/3x3_s1
I0413 19:14:43.339987 11754 net.cpp:113] Setting up conv1/3x3_s1
I0413 19:14:43.340420 11754 net.cpp:120] Top shape: 128 64 222 222 (403734528)
I0413 19:14:43.340433 11754 layer_factory.hpp:74] Creating layer conv1/relu
I0413 19:14:43.340440 11754 net.cpp:84] Creating Layer conv1/relu
I0413 19:14:43.340443 11754 net.cpp:380] conv1/relu <- conv1/3x3_s1
I0413 19:14:43.340447 11754 net.cpp:327] conv1/relu -> conv1/3x3_s1 (in-place)
I0413 19:14:43.340451 11754 net.cpp:113] Setting up conv1/relu
I0413 19:14:43.340461 11754 net.cpp:120] Top shape: 128 64 222 222 (403734528)
I0413 19:14:43.340463 11754 layer_factory.hpp:74] Creating layer pool1/2x2_s2
I0413 19:14:43.340468 11754 net.cpp:84] Creating Layer pool1/2x2_s2
I0413 19:14:43.340471 11754 net.cpp:380] pool1/2x2_s2 <- conv1/3x3_s1
I0413 19:14:43.340476 11754 net.cpp:338] pool1/2x2_s2 -> pool1/2x2_s2
I0413 19:14:43.340481 11754 net.cpp:113] Setting up pool1/2x2_s2
I0413 19:14:43.340492 11754 net.cpp:120] Top shape: 128 64 111 111 (100933632)
I0413 19:14:43.340497 11754 layer_factory.hpp:74] Creating layer conv2/3x3_s1
I0413 19:14:43.340502 11754 net.cpp:84] Creating Layer conv2/3x3_s1
I0413 19:14:43.340505 11754 net.cpp:380] conv2/3x3_s1 <- pool1/2x2_s2
I0413 19:14:43.340509 11754 net.cpp:338] conv2/3x3_s1 -> conv2/3x3_s1
I0413 19:14:43.340514 11754 net.cpp:113] Setting up conv2/3x3_s1
I0413 19:14:43.340991 11754 net.cpp:120] Top shape: 128 128 111 111 (201867264)
I0413 19:14:43.340998 11754 layer_factory.hpp:74] Creating layer conv2/relu
I0413 19:14:43.341003 11754 net.cpp:84] Creating Layer conv2/relu
I0413 19:14:43.341006 11754 net.cpp:380] conv2/relu <- conv2/3x3_s1
I0413 19:14:43.341013 11754 net.cpp:327] conv2/relu -> conv2/3x3_s1 (in-place)
I0413 19:14:43.341018 11754 net.cpp:113] Setting up conv2/relu
I0413 19:14:43.341022 11754 net.cpp:120] Top shape: 128 128 111 111 (201867264)
I0413 19:14:43.341025 11754 layer_factory.hpp:74] Creating layer pool2/2x2_s2
I0413 19:14:43.341029 11754 net.cpp:84] Creating Layer pool2/2x2_s2
I0413 19:14:43.341037 11754 net.cpp:380] pool2/2x2_s2 <- conv2/3x3_s1
I0413 19:14:43.341040 11754 net.cpp:338] pool2/2x2_s2 -> pool2/2x2_s2
I0413 19:14:43.341045 11754 net.cpp:113] Setting up pool2/2x2_s2
I0413 19:14:43.341050 11754 net.cpp:120] Top shape: 128 128 56 56 (51380224)
I0413 19:14:43.341053 11754 layer_factory.hpp:74] Creating layer conv3/3x3_s1
I0413 19:14:43.341059 11754 net.cpp:84] Creating Layer conv3/3x3_s1
I0413 19:14:43.341063 11754 net.cpp:380] conv3/3x3_s1 <- pool2/2x2_s2
I0413 19:14:43.341068 11754 net.cpp:338] conv3/3x3_s1 -> conv3/3x3_s1
I0413 19:14:43.341073 11754 net.cpp:113] Setting up conv3/3x3_s1
I0413 19:14:43.342875 11754 net.cpp:120] Top shape: 128 256 56 56 (102760448)
I0413 19:14:43.342885 11754 layer_factory.hpp:74] Creating layer conv3/relu
I0413 19:14:43.342888 11754 net.cpp:84] Creating Layer conv3/relu
I0413 19:14:43.342891 11754 net.cpp:380] conv3/relu <- conv3/3x3_s1
I0413 19:14:43.342895 11754 net.cpp:327] conv3/relu -> conv3/3x3_s1 (in-place)
I0413 19:14:43.342900 11754 net.cpp:113] Setting up conv3/relu
I0413 19:14:43.342903 11754 net.cpp:120] Top shape: 128 256 56 56 (102760448)
I0413 19:14:43.342906 11754 layer_factory.hpp:74] Creating layer conv4/3x3_s1
I0413 19:14:43.342912 11754 net.cpp:84] Creating Layer conv4/3x3_s1
I0413 19:14:43.342916 11754 net.cpp:380] conv4/3x3_s1 <- conv3/3x3_s1
I0413 19:14:43.342919 11754 net.cpp:338] conv4/3x3_s1 -> conv4/3x3_s1
I0413 19:14:43.342924 11754 net.cpp:113] Setting up conv4/3x3_s1
I0413 19:14:43.346514 11754 net.cpp:120] Top shape: 128 256 56 56 (102760448)
I0413 19:14:43.346524 11754 layer_factory.hpp:74] Creating layer conv4/relu
I0413 19:14:43.346529 11754 net.cpp:84] Creating Layer conv4/relu
I0413 19:14:43.346531 11754 net.cpp:380] conv4/relu <- conv4/3x3_s1
I0413 19:14:43.346535 11754 net.cpp:327] conv4/relu -> conv4/3x3_s1 (in-place)
I0413 19:14:43.346539 11754 net.cpp:113] Setting up conv4/relu
I0413 19:14:43.346544 11754 net.cpp:120] Top shape: 128 256 56 56 (102760448)
I0413 19:14:43.346546 11754 layer_factory.hpp:74] Creating layer pool3/2x2_s2
I0413 19:14:43.346550 11754 net.cpp:84] Creating Layer pool3/2x2_s2
I0413 19:14:43.346552 11754 net.cpp:380] pool3/2x2_s2 <- conv4/3x3_s1
I0413 19:14:43.346557 11754 net.cpp:338] pool3/2x2_s2 -> pool3/2x2_s2
I0413 19:14:43.346562 11754 net.cpp:113] Setting up pool3/2x2_s2
I0413 19:14:43.346567 11754 net.cpp:120] Top shape: 128 256 28 28 (25690112)
I0413 19:14:43.346570 11754 layer_factory.hpp:74] Creating layer conv5/3x3_s1
I0413 19:14:43.346576 11754 net.cpp:84] Creating Layer conv5/3x3_s1
I0413 19:14:43.346580 11754 net.cpp:380] conv5/3x3_s1 <- pool3/2x2_s2
I0413 19:14:43.346583 11754 net.cpp:338] conv5/3x3_s1 -> conv5/3x3_s1
I0413 19:14:43.346588 11754 net.cpp:113] Setting up conv5/3x3_s1
I0413 19:14:43.353413 11754 net.cpp:120] Top shape: 128 512 28 28 (51380224)
I0413 19:14:43.353425 11754 layer_factory.hpp:74] Creating layer conv5/relu
I0413 19:14:43.353430 11754 net.cpp:84] Creating Layer conv5/relu
I0413 19:14:43.353432 11754 net.cpp:380] conv5/relu <- conv5/3x3_s1
I0413 19:14:43.353436 11754 net.cpp:327] conv5/relu -> conv5/3x3_s1 (in-place)
I0413 19:14:43.353441 11754 net.cpp:113] Setting up conv5/relu
I0413 19:14:43.353446 11754 net.cpp:120] Top shape: 128 512 28 28 (51380224)
I0413 19:14:43.353448 11754 layer_factory.hpp:74] Creating layer conv6/3x3_s1
I0413 19:14:43.353453 11754 net.cpp:84] Creating Layer conv6/3x3_s1
I0413 19:14:43.353456 11754 net.cpp:380] conv6/3x3_s1 <- conv5/3x3_s1
I0413 19:14:43.353461 11754 net.cpp:338] conv6/3x3_s1 -> conv6/3x3_s1
I0413 19:14:43.353466 11754 net.cpp:113] Setting up conv6/3x3_s1
I0413 19:14:43.366715 11754 net.cpp:120] Top shape: 128 512 28 28 (51380224)
I0413 19:14:43.366727 11754 layer_factory.hpp:74] Creating layer conv6/relu
I0413 19:14:43.366732 11754 net.cpp:84] Creating Layer conv6/relu
I0413 19:14:43.366735 11754 net.cpp:380] conv6/relu <- conv6/3x3_s1
I0413 19:14:43.366739 11754 net.cpp:327] conv6/relu -> conv6/3x3_s1 (in-place)
I0413 19:14:43.366744 11754 net.cpp:113] Setting up conv6/relu
I0413 19:14:43.366755 11754 net.cpp:120] Top shape: 128 512 28 28 (51380224)
I0413 19:14:43.366757 11754 layer_factory.hpp:74] Creating layer pool4/2x2_s2
I0413 19:14:43.366765 11754 net.cpp:84] Creating Layer pool4/2x2_s2
I0413 19:14:43.366766 11754 net.cpp:380] pool4/2x2_s2 <- conv6/3x3_s1
I0413 19:14:43.366770 11754 net.cpp:338] pool4/2x2_s2 -> pool4/2x2_s2
I0413 19:14:43.366775 11754 net.cpp:113] Setting up pool4/2x2_s2
I0413 19:14:43.366782 11754 net.cpp:120] Top shape: 128 512 14 14 (12845056)
I0413 19:14:43.366786 11754 layer_factory.hpp:74] Creating layer conv7/3x3_s1
I0413 19:14:43.366792 11754 net.cpp:84] Creating Layer conv7/3x3_s1
I0413 19:14:43.366796 11754 net.cpp:380] conv7/3x3_s1 <- pool4/2x2_s2
I0413 19:14:43.366801 11754 net.cpp:338] conv7/3x3_s1 -> conv7/3x3_s1
I0413 19:14:43.366806 11754 net.cpp:113] Setting up conv7/3x3_s1
I0413 19:14:43.379739 11754 net.cpp:120] Top shape: 128 512 14 14 (12845056)
I0413 19:14:43.379753 11754 layer_factory.hpp:74] Creating layer conv7/relu
I0413 19:14:43.379761 11754 net.cpp:84] Creating Layer conv7/relu
I0413 19:14:43.379765 11754 net.cpp:380] conv7/relu <- conv7/3x3_s1
I0413 19:14:43.379768 11754 net.cpp:327] conv7/relu -> conv7/3x3_s1 (in-place)
I0413 19:14:43.379773 11754 net.cpp:113] Setting up conv7/relu
I0413 19:14:43.379777 11754 net.cpp:120] Top shape: 128 512 14 14 (12845056)
I0413 19:14:43.379781 11754 layer_factory.hpp:74] Creating layer conv8/3x3_s1
I0413 19:14:43.379786 11754 net.cpp:84] Creating Layer conv8/3x3_s1
I0413 19:14:43.379788 11754 net.cpp:380] conv8/3x3_s1 <- conv7/3x3_s1
I0413 19:14:43.379792 11754 net.cpp:338] conv8/3x3_s1 -> conv8/3x3_s1
I0413 19:14:43.379797 11754 net.cpp:113] Setting up conv8/3x3_s1
I0413 19:14:43.392680 11754 net.cpp:120] Top shape: 128 512 14 14 (12845056)
I0413 19:14:43.392691 11754 layer_factory.hpp:74] Creating layer conv8/relu
I0413 19:14:43.392698 11754 net.cpp:84] Creating Layer conv8/relu
I0413 19:14:43.392700 11754 net.cpp:380] conv8/relu <- conv8/3x3_s1
I0413 19:14:43.392704 11754 net.cpp:327] conv8/relu -> conv8/3x3_s1 (in-place)
I0413 19:14:43.392709 11754 net.cpp:113] Setting up conv8/relu
I0413 19:14:43.392712 11754 net.cpp:120] Top shape: 128 512 14 14 (12845056)
I0413 19:14:43.392715 11754 layer_factory.hpp:74] Creating layer pool5/2x2_s2
I0413 19:14:43.392722 11754 net.cpp:84] Creating Layer pool5/2x2_s2
I0413 19:14:43.392725 11754 net.cpp:380] pool5/2x2_s2 <- conv8/3x3_s1
I0413 19:14:43.392729 11754 net.cpp:338] pool5/2x2_s2 -> pool5/2x2_s2
I0413 19:14:43.392734 11754 net.cpp:113] Setting up pool5/2x2_s2
I0413 19:14:43.392740 11754 net.cpp:120] Top shape: 128 512 7 7 (3211264)
I0413 19:14:43.392742 11754 layer_factory.hpp:74] Creating layer fc6-conv
I0413 19:14:43.392747 11754 net.cpp:84] Creating Layer fc6-conv
I0413 19:14:43.392750 11754 net.cpp:380] fc6-conv <- pool5/2x2_s2
I0413 19:14:43.392753 11754 net.cpp:338] fc6-conv -> fc6-conv
I0413 19:14:43.392758 11754 net.cpp:113] Setting up fc6-conv
I0413 19:14:43.633944 11754 net.cpp:120] Top shape: 128 4096 1 1 (524288)
I0413 19:14:43.633975 11754 layer_factory.hpp:74] Creating layer fc7-conv
I0413 19:14:43.633983 11754 net.cpp:84] Creating Layer fc7-conv
I0413 19:14:43.633987 11754 net.cpp:380] fc7-conv <- fc6-conv
I0413 19:14:43.633994 11754 net.cpp:338] fc7-conv -> fc7-conv
I0413 19:14:43.634001 11754 net.cpp:113] Setting up fc7-conv
I0413 19:14:43.791873 11754 net.cpp:120] Top shape: 128 4096 1 1 (524288)
I0413 19:14:43.791896 11754 layer_factory.hpp:74] Creating layer fc8-conv
I0413 19:14:43.791913 11754 net.cpp:84] Creating Layer fc8-conv
I0413 19:14:43.791918 11754 net.cpp:380] fc8-conv <- fc7-conv
I0413 19:14:43.791923 11754 net.cpp:338] fc8-conv -> fc8
I0413 19:14:43.791934 11754 net.cpp:113] Setting up fc8-conv
I0413 19:14:43.823463 11754 net.cpp:120] Top shape: 128 1000 1 1 (128000)
I0413 19:14:43.823487 11754 net.cpp:169] fc8-conv does not need backward computation.
I0413 19:14:43.823489 11754 net.cpp:169] fc7-conv does not need backward computation.
I0413 19:14:43.823493 11754 net.cpp:169] fc6-conv does not need backward computation.
I0413 19:14:43.823503 11754 net.cpp:169] pool5/2x2_s2 does not need backward computation.
I0413 19:14:43.823505 11754 net.cpp:169] conv8/relu does not need backward computation.
I0413 19:14:43.823508 11754 net.cpp:169] conv8/3x3_s1 does not need backward computation.
I0413 19:14:43.823511 11754 net.cpp:169] conv7/relu does not need backward computation.
I0413 19:14:43.823513 11754 net.cpp:169] conv7/3x3_s1 does not need backward computation.
I0413 19:14:43.823516 11754 net.cpp:169] pool4/2x2_s2 does not need backward computation.
I0413 19:14:43.823519 11754 net.cpp:169] conv6/relu does not need backward computation.
I0413 19:14:43.823521 11754 net.cpp:169] conv6/3x3_s1 does not need backward computation.
I0413 19:14:43.823524 11754 net.cpp:169] conv5/relu does not need backward computation.
I0413 19:14:43.823526 11754 net.cpp:169] conv5/3x3_s1 does not need backward computation.
I0413 19:14:43.823529 11754 net.cpp:169] pool3/2x2_s2 does not need backward computation.
I0413 19:14:43.823531 11754 net.cpp:169] conv4/relu does not need backward computation.
I0413 19:14:43.823534 11754 net.cpp:169] conv4/3x3_s1 does not need backward computation.
I0413 19:14:43.823537 11754 net.cpp:169] conv3/relu does not need backward computation.
I0413 19:14:43.823539 11754 net.cpp:169] conv3/3x3_s1 does not need backward computation.
I0413 19:14:43.823542 11754 net.cpp:169] pool2/2x2_s2 does not need backward computation.
I0413 19:14:43.823544 11754 net.cpp:169] conv2/relu does not need backward computation.
I0413 19:14:43.823547 11754 net.cpp:169] conv2/3x3_s1 does not need backward computation.
I0413 19:14:43.823549 11754 net.cpp:169] pool1/2x2_s2 does not need backward computation.
I0413 19:14:43.823552 11754 net.cpp:169] conv1/relu does not need backward computation.
I0413 19:14:43.823554 11754 net.cpp:169] conv1/3x3_s1 does not need backward computation.
I0413 19:14:43.823559 11754 net.cpp:205] This network produces output fc8
I0413 19:14:43.823585 11754 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0413 19:14:43.823591 11754 net.cpp:217] Network initialization done.
I0413 19:14:43.823595 11754 net.cpp:218] Memory required for data: 8297533440
I0413 19:14:43.823676 11754 caffe.cpp:224] Performing Forward
I0413 19:14:45.105893 11754 caffe.cpp:229] Initial loss: 0
I0413 19:14:45.105932 11754 caffe.cpp:230] Performing Backward
I0413 19:14:47.506567 11754 caffe.cpp:238] *** Benchmark begins ***
I0413 19:14:47.506577 11754 caffe.cpp:239] Testing for 10 iterations.
I0413 19:14:51.610297 11754 caffe.cpp:270] Iteration: 1 forward-backward time: 3846 ms.
I0413 19:14:55.457885 11754 caffe.cpp:270] Iteration: 2 forward-backward time: 3847.47 ms.
I0413 19:14:59.305120 11754 caffe.cpp:270] Iteration: 3 forward-backward time: 3847.13 ms.
I0413 19:15:03.154336 11754 caffe.cpp:270] Iteration: 4 forward-backward time: 3849.12 ms.
I0413 19:15:07.001637 11754 caffe.cpp:270] Iteration: 5 forward-backward time: 3847.2 ms.
I0413 19:15:10.855232 11754 caffe.cpp:270] Iteration: 6 forward-backward time: 3853.49 ms.
I0413 19:15:14.706902 11754 caffe.cpp:270] Iteration: 7 forward-backward time: 3851.55 ms.
I0413 19:15:18.562708 11754 caffe.cpp:270] Iteration: 8 forward-backward time: 3855.68 ms.
I0413 19:15:22.420666 11754 caffe.cpp:270] Iteration: 9 forward-backward time: 3857.83 ms.
I0413 19:15:26.299160 11754 caffe.cpp:270] Iteration: 10 forward-backward time: 3878.37 ms.
I0413 19:15:26.299187 11754 caffe.cpp:273] Average time per layer: 
I0413 19:15:26.299191 11754 caffe.cpp:276] conv1/3x3_s1	forward: 37.4927 ms.
I0413 19:15:26.299196 11754 caffe.cpp:279] conv1/3x3_s1	backward: 152.41 ms.
I0413 19:15:26.299199 11754 caffe.cpp:276] conv1/relu	forward: 12.7286 ms.
I0413 19:15:26.299203 11754 caffe.cpp:279] conv1/relu	backward: 18.8843 ms.
I0413 19:15:26.299206 11754 caffe.cpp:276] pool1/2x2_s2	forward: 9.79517 ms.
I0413 19:15:26.299211 11754 caffe.cpp:279] pool1/2x2_s2	backward: 50.5825 ms.
I0413 19:15:26.299213 11754 caffe.cpp:276] conv2/3x3_s1	forward: 74.1761 ms.
I0413 19:15:26.299217 11754 caffe.cpp:279] conv2/3x3_s1	backward: 262.042 ms.
I0413 19:15:26.299221 11754 caffe.cpp:276] conv2/relu	forward: 6.36784 ms.
I0413 19:15:26.299231 11754 caffe.cpp:279] conv2/relu	backward: 9.44599 ms.
I0413 19:15:26.299233 11754 caffe.cpp:276] pool2/2x2_s2	forward: 4.95452 ms.
I0413 19:15:26.299237 11754 caffe.cpp:279] pool2/2x2_s2	backward: 25.2863 ms.
I0413 19:15:26.299239 11754 caffe.cpp:276] conv3/3x3_s1	forward: 61.9178 ms.
I0413 19:15:26.299242 11754 caffe.cpp:279] conv3/3x3_s1	backward: 139.317 ms.
I0413 19:15:26.299245 11754 caffe.cpp:276] conv3/relu	forward: 3.2462 ms.
I0413 19:15:26.299248 11754 caffe.cpp:279] conv3/relu	backward: 4.80973 ms.
I0413 19:15:26.299252 11754 caffe.cpp:276] conv4/3x3_s1	forward: 113.951 ms.
I0413 19:15:26.299254 11754 caffe.cpp:279] conv4/3x3_s1	backward: 223.173 ms.
I0413 19:15:26.299257 11754 caffe.cpp:276] conv4/relu	forward: 3.24679 ms.
I0413 19:15:26.299260 11754 caffe.cpp:279] conv4/relu	backward: 4.81507 ms.
I0413 19:15:26.299263 11754 caffe.cpp:276] pool3/2x2_s2	forward: 2.49005 ms.
I0413 19:15:26.299267 11754 caffe.cpp:279] pool3/2x2_s2	backward: 12.858 ms.
I0413 19:15:26.299269 11754 caffe.cpp:276] conv5/3x3_s1	forward: 52.9796 ms.
I0413 19:15:26.299273 11754 caffe.cpp:279] conv5/3x3_s1	backward: 118.269 ms.
I0413 19:15:26.299275 11754 caffe.cpp:276] conv5/relu	forward: 1.62764 ms.
I0413 19:15:26.299278 11754 caffe.cpp:279] conv5/relu	backward: 2.40681 ms.
I0413 19:15:26.299281 11754 caffe.cpp:276] conv6/3x3_s1	forward: 102.72 ms.
I0413 19:15:26.299284 11754 caffe.cpp:279] conv6/3x3_s1	backward: 214.933 ms.
I0413 19:15:26.299288 11754 caffe.cpp:276] conv6/relu	forward: 1.62702 ms.
I0413 19:15:26.299290 11754 caffe.cpp:279] conv6/relu	backward: 2.41193 ms.
I0413 19:15:26.299293 11754 caffe.cpp:276] pool4/2x2_s2	forward: 1.29115 ms.
I0413 19:15:26.299295 11754 caffe.cpp:279] pool4/2x2_s2	backward: 6.43215 ms.
I0413 19:15:26.299299 11754 caffe.cpp:276] conv7/3x3_s1	forward: 83.2002 ms.
I0413 19:15:26.299301 11754 caffe.cpp:279] conv7/3x3_s1	backward: 119.403 ms.
I0413 19:15:26.299304 11754 caffe.cpp:276] conv7/relu	forward: 0.408906 ms.
I0413 19:15:26.299309 11754 caffe.cpp:279] conv7/relu	backward: 0.604973 ms.
I0413 19:15:26.299311 11754 caffe.cpp:276] conv8/3x3_s1	forward: 82.8715 ms.
I0413 19:15:26.299314 11754 caffe.cpp:279] conv8/3x3_s1	backward: 119.446 ms.
I0413 19:15:26.299317 11754 caffe.cpp:276] conv8/relu	forward: 0.408784 ms.
I0413 19:15:26.299320 11754 caffe.cpp:279] conv8/relu	backward: 0.609386 ms.
I0413 19:15:26.299322 11754 caffe.cpp:276] pool5/2x2_s2	forward: 0.349094 ms.
I0413 19:15:26.299325 11754 caffe.cpp:279] pool5/2x2_s2	backward: 1.62714 ms.
I0413 19:15:26.299329 11754 caffe.cpp:276]   fc6-conv	forward: 482.737 ms.
I0413 19:15:26.299331 11754 caffe.cpp:279]   fc6-conv	backward: 940.095 ms.
I0413 19:15:26.299335 11754 caffe.cpp:276]   fc7-conv	forward: 75.9876 ms.
I0413 19:15:26.299338 11754 caffe.cpp:279]   fc7-conv	backward: 145.777 ms.
I0413 19:15:26.299341 11754 caffe.cpp:276]   fc8-conv	forward: 23.0085 ms.
I0413 19:15:26.299345 11754 caffe.cpp:279]   fc8-conv	backward: 37.7553 ms.
I0413 19:15:26.299356 11754 caffe.cpp:284] Average Forward pass: 1239.78 ms.
I0413 19:15:26.299360 11754 caffe.cpp:286] Average Backward pass: 2613.6 ms.
I0413 19:15:26.299365 11754 caffe.cpp:288] Average Forward-Backward: 3853.43 ms.
I0413 19:15:26.299370 11754 caffe.cpp:290] Total Time: 38534.3 ms.
I0413 19:15:26.299372 11754 caffe.cpp:291] *** Benchmark ends ***
I0415 15:47:46.789175 32485 caffe.cpp:212] Use GPU with device ID 0
E0415 15:47:46.985782 32485 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/vgg_a.prototxt
I0415 15:47:46.985868 32485 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0415 15:47:46.986053 32485 net.cpp:42] Initializing net from parameters: 
name: "vgg_a"
input: "data"
input_dim: 64
input_dim: 3
input_dim: 224
input_dim: 224
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "pool1/2x2_s2"
  type: "Pooling"
  bottom: "conv1/3x3_s1"
  top: "pool1/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2/3x3_s1"
  type: "Convolution"
  bottom: "pool1/2x2_s2"
  top: "conv2/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2/3x3_s1"
  top: "conv2/3x3_s1"
}
layer {
  name: "pool2/2x2_s2"
  type: "Pooling"
  bottom: "conv2/3x3_s1"
  top: "pool2/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/2x2_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "pool3/2x2_s2"
  type: "Pooling"
  bottom: "conv4/3x3_s1"
  top: "pool3/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "pool3/2x2_s2"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "conv6/3x3_s1"
  type: "Convolution"
  bottom: "conv5/3x3_s1"
  top: "conv6/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6/3x3_s1"
  top: "conv6/3x3_s1"
}
layer {
  name: "pool4/2x2_s2"
  type: "Pooling"
  bottom: "conv6/3x3_s1"
  top: "pool4/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv7/3x3_s1"
  type: "Convolution"
  bottom: "pool4/2x2_s2"
  top: "conv7/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7/3x3_s1"
  top: "conv7/3x3_s1"
}
layer {
  name: "conv8/3x3_s1"
  type: "Convolution"
  bottom: "conv7/3x3_s1"
  top: "conv8/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8/3x3_s1"
  top: "conv8/3x3_s1"
}
layer {
  name: "pool5/2x2_s2"
  type: "Pooling"
  bottom: "conv8/3x3_s1"
  top: "pool5/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5/2x2_s2"
  top: "fc6-conv"
  convolution_param {
    num_output: 4096
    kernel_size: 7
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "fc8-conv"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8"
  convolution_param {
    num_output: 1000
    kernel_size: 1
  }
}
I0415 15:47:46.986135 32485 net.cpp:340] Input 0 -> data
I0415 15:47:46.986166 32485 layer_factory.hpp:74] Creating layer conv1/3x3_s1
I0415 15:47:46.986181 32485 net.cpp:84] Creating Layer conv1/3x3_s1
I0415 15:47:46.986186 32485 net.cpp:380] conv1/3x3_s1 <- data
I0415 15:47:46.986192 32485 net.cpp:338] conv1/3x3_s1 -> conv1/3x3_s1
I0415 15:47:46.986202 32485 net.cpp:113] Setting up conv1/3x3_s1
I0415 15:47:46.986637 32485 net.cpp:120] Top shape: 64 64 222 222 (201867264)
I0415 15:47:46.986650 32485 layer_factory.hpp:74] Creating layer conv1/relu
I0415 15:47:46.986657 32485 net.cpp:84] Creating Layer conv1/relu
I0415 15:47:46.986660 32485 net.cpp:380] conv1/relu <- conv1/3x3_s1
I0415 15:47:46.986665 32485 net.cpp:327] conv1/relu -> conv1/3x3_s1 (in-place)
I0415 15:47:46.986670 32485 net.cpp:113] Setting up conv1/relu
I0415 15:47:46.986678 32485 net.cpp:120] Top shape: 64 64 222 222 (201867264)
I0415 15:47:46.986681 32485 layer_factory.hpp:74] Creating layer pool1/2x2_s2
I0415 15:47:46.986687 32485 net.cpp:84] Creating Layer pool1/2x2_s2
I0415 15:47:46.986690 32485 net.cpp:380] pool1/2x2_s2 <- conv1/3x3_s1
I0415 15:47:46.986695 32485 net.cpp:338] pool1/2x2_s2 -> pool1/2x2_s2
I0415 15:47:46.986699 32485 net.cpp:113] Setting up pool1/2x2_s2
I0415 15:47:46.986711 32485 net.cpp:120] Top shape: 64 64 111 111 (50466816)
I0415 15:47:46.986716 32485 layer_factory.hpp:74] Creating layer conv2/3x3_s1
I0415 15:47:46.986721 32485 net.cpp:84] Creating Layer conv2/3x3_s1
I0415 15:47:46.986722 32485 net.cpp:380] conv2/3x3_s1 <- pool1/2x2_s2
I0415 15:47:46.986727 32485 net.cpp:338] conv2/3x3_s1 -> conv2/3x3_s1
I0415 15:47:46.986732 32485 net.cpp:113] Setting up conv2/3x3_s1
I0415 15:47:46.987207 32485 net.cpp:120] Top shape: 64 128 111 111 (100933632)
I0415 15:47:46.987217 32485 layer_factory.hpp:74] Creating layer conv2/relu
I0415 15:47:46.987224 32485 net.cpp:84] Creating Layer conv2/relu
I0415 15:47:46.987227 32485 net.cpp:380] conv2/relu <- conv2/3x3_s1
I0415 15:47:46.987231 32485 net.cpp:327] conv2/relu -> conv2/3x3_s1 (in-place)
I0415 15:47:46.987236 32485 net.cpp:113] Setting up conv2/relu
I0415 15:47:46.987239 32485 net.cpp:120] Top shape: 64 128 111 111 (100933632)
I0415 15:47:46.987242 32485 layer_factory.hpp:74] Creating layer pool2/2x2_s2
I0415 15:47:46.987246 32485 net.cpp:84] Creating Layer pool2/2x2_s2
I0415 15:47:46.987249 32485 net.cpp:380] pool2/2x2_s2 <- conv2/3x3_s1
I0415 15:47:46.987254 32485 net.cpp:338] pool2/2x2_s2 -> pool2/2x2_s2
I0415 15:47:46.987259 32485 net.cpp:113] Setting up pool2/2x2_s2
I0415 15:47:46.987265 32485 net.cpp:120] Top shape: 64 128 56 56 (25690112)
I0415 15:47:46.987268 32485 layer_factory.hpp:74] Creating layer conv3/3x3_s1
I0415 15:47:46.987273 32485 net.cpp:84] Creating Layer conv3/3x3_s1
I0415 15:47:46.987275 32485 net.cpp:380] conv3/3x3_s1 <- pool2/2x2_s2
I0415 15:47:46.987282 32485 net.cpp:338] conv3/3x3_s1 -> conv3/3x3_s1
I0415 15:47:46.987287 32485 net.cpp:113] Setting up conv3/3x3_s1
I0415 15:47:46.989044 32485 net.cpp:120] Top shape: 64 256 56 56 (51380224)
I0415 15:47:46.989058 32485 layer_factory.hpp:74] Creating layer conv3/relu
I0415 15:47:46.989063 32485 net.cpp:84] Creating Layer conv3/relu
I0415 15:47:46.989064 32485 net.cpp:380] conv3/relu <- conv3/3x3_s1
I0415 15:47:46.989069 32485 net.cpp:327] conv3/relu -> conv3/3x3_s1 (in-place)
I0415 15:47:46.989074 32485 net.cpp:113] Setting up conv3/relu
I0415 15:47:46.989078 32485 net.cpp:120] Top shape: 64 256 56 56 (51380224)
I0415 15:47:46.989081 32485 layer_factory.hpp:74] Creating layer conv4/3x3_s1
I0415 15:47:46.989086 32485 net.cpp:84] Creating Layer conv4/3x3_s1
I0415 15:47:46.989089 32485 net.cpp:380] conv4/3x3_s1 <- conv3/3x3_s1
I0415 15:47:46.989094 32485 net.cpp:338] conv4/3x3_s1 -> conv4/3x3_s1
I0415 15:47:46.989099 32485 net.cpp:113] Setting up conv4/3x3_s1
I0415 15:47:46.992606 32485 net.cpp:120] Top shape: 64 256 56 56 (51380224)
I0415 15:47:46.992615 32485 layer_factory.hpp:74] Creating layer conv4/relu
I0415 15:47:46.992620 32485 net.cpp:84] Creating Layer conv4/relu
I0415 15:47:46.992624 32485 net.cpp:380] conv4/relu <- conv4/3x3_s1
I0415 15:47:46.992627 32485 net.cpp:327] conv4/relu -> conv4/3x3_s1 (in-place)
I0415 15:47:46.992631 32485 net.cpp:113] Setting up conv4/relu
I0415 15:47:46.992635 32485 net.cpp:120] Top shape: 64 256 56 56 (51380224)
I0415 15:47:46.992638 32485 layer_factory.hpp:74] Creating layer pool3/2x2_s2
I0415 15:47:46.992643 32485 net.cpp:84] Creating Layer pool3/2x2_s2
I0415 15:47:46.992646 32485 net.cpp:380] pool3/2x2_s2 <- conv4/3x3_s1
I0415 15:47:46.992650 32485 net.cpp:338] pool3/2x2_s2 -> pool3/2x2_s2
I0415 15:47:46.992655 32485 net.cpp:113] Setting up pool3/2x2_s2
I0415 15:47:46.992660 32485 net.cpp:120] Top shape: 64 256 28 28 (12845056)
I0415 15:47:46.992663 32485 layer_factory.hpp:74] Creating layer conv5/3x3_s1
I0415 15:47:46.992668 32485 net.cpp:84] Creating Layer conv5/3x3_s1
I0415 15:47:46.992671 32485 net.cpp:380] conv5/3x3_s1 <- pool3/2x2_s2
I0415 15:47:46.992676 32485 net.cpp:338] conv5/3x3_s1 -> conv5/3x3_s1
I0415 15:47:46.992681 32485 net.cpp:113] Setting up conv5/3x3_s1
I0415 15:47:46.999440 32485 net.cpp:120] Top shape: 64 512 28 28 (25690112)
I0415 15:47:46.999451 32485 layer_factory.hpp:74] Creating layer conv5/relu
I0415 15:47:46.999457 32485 net.cpp:84] Creating Layer conv5/relu
I0415 15:47:46.999460 32485 net.cpp:380] conv5/relu <- conv5/3x3_s1
I0415 15:47:46.999464 32485 net.cpp:327] conv5/relu -> conv5/3x3_s1 (in-place)
I0415 15:47:46.999469 32485 net.cpp:113] Setting up conv5/relu
I0415 15:47:46.999472 32485 net.cpp:120] Top shape: 64 512 28 28 (25690112)
I0415 15:47:46.999475 32485 layer_factory.hpp:74] Creating layer conv6/3x3_s1
I0415 15:47:46.999481 32485 net.cpp:84] Creating Layer conv6/3x3_s1
I0415 15:47:46.999485 32485 net.cpp:380] conv6/3x3_s1 <- conv5/3x3_s1
I0415 15:47:46.999488 32485 net.cpp:338] conv6/3x3_s1 -> conv6/3x3_s1
I0415 15:47:46.999493 32485 net.cpp:113] Setting up conv6/3x3_s1
I0415 15:47:47.012390 32485 net.cpp:120] Top shape: 64 512 28 28 (25690112)
I0415 15:47:47.012403 32485 layer_factory.hpp:74] Creating layer conv6/relu
I0415 15:47:47.012408 32485 net.cpp:84] Creating Layer conv6/relu
I0415 15:47:47.012410 32485 net.cpp:380] conv6/relu <- conv6/3x3_s1
I0415 15:47:47.012415 32485 net.cpp:327] conv6/relu -> conv6/3x3_s1 (in-place)
I0415 15:47:47.012420 32485 net.cpp:113] Setting up conv6/relu
I0415 15:47:47.012424 32485 net.cpp:120] Top shape: 64 512 28 28 (25690112)
I0415 15:47:47.012428 32485 layer_factory.hpp:74] Creating layer pool4/2x2_s2
I0415 15:47:47.012431 32485 net.cpp:84] Creating Layer pool4/2x2_s2
I0415 15:47:47.012434 32485 net.cpp:380] pool4/2x2_s2 <- conv6/3x3_s1
I0415 15:47:47.012439 32485 net.cpp:338] pool4/2x2_s2 -> pool4/2x2_s2
I0415 15:47:47.012444 32485 net.cpp:113] Setting up pool4/2x2_s2
I0415 15:47:47.012449 32485 net.cpp:120] Top shape: 64 512 14 14 (6422528)
I0415 15:47:47.012452 32485 layer_factory.hpp:74] Creating layer conv7/3x3_s1
I0415 15:47:47.012459 32485 net.cpp:84] Creating Layer conv7/3x3_s1
I0415 15:47:47.012461 32485 net.cpp:380] conv7/3x3_s1 <- pool4/2x2_s2
I0415 15:47:47.012475 32485 net.cpp:338] conv7/3x3_s1 -> conv7/3x3_s1
I0415 15:47:47.012480 32485 net.cpp:113] Setting up conv7/3x3_s1
I0415 15:47:47.025348 32485 net.cpp:120] Top shape: 64 512 14 14 (6422528)
I0415 15:47:47.025363 32485 layer_factory.hpp:74] Creating layer conv7/relu
I0415 15:47:47.025369 32485 net.cpp:84] Creating Layer conv7/relu
I0415 15:47:47.025372 32485 net.cpp:380] conv7/relu <- conv7/3x3_s1
I0415 15:47:47.025377 32485 net.cpp:327] conv7/relu -> conv7/3x3_s1 (in-place)
I0415 15:47:47.025380 32485 net.cpp:113] Setting up conv7/relu
I0415 15:47:47.025385 32485 net.cpp:120] Top shape: 64 512 14 14 (6422528)
I0415 15:47:47.025388 32485 layer_factory.hpp:74] Creating layer conv8/3x3_s1
I0415 15:47:47.025394 32485 net.cpp:84] Creating Layer conv8/3x3_s1
I0415 15:47:47.025398 32485 net.cpp:380] conv8/3x3_s1 <- conv7/3x3_s1
I0415 15:47:47.025401 32485 net.cpp:338] conv8/3x3_s1 -> conv8/3x3_s1
I0415 15:47:47.025408 32485 net.cpp:113] Setting up conv8/3x3_s1
I0415 15:47:47.038519 32485 net.cpp:120] Top shape: 64 512 14 14 (6422528)
I0415 15:47:47.038532 32485 layer_factory.hpp:74] Creating layer conv8/relu
I0415 15:47:47.038537 32485 net.cpp:84] Creating Layer conv8/relu
I0415 15:47:47.038539 32485 net.cpp:380] conv8/relu <- conv8/3x3_s1
I0415 15:47:47.038544 32485 net.cpp:327] conv8/relu -> conv8/3x3_s1 (in-place)
I0415 15:47:47.038549 32485 net.cpp:113] Setting up conv8/relu
I0415 15:47:47.038553 32485 net.cpp:120] Top shape: 64 512 14 14 (6422528)
I0415 15:47:47.038557 32485 layer_factory.hpp:74] Creating layer pool5/2x2_s2
I0415 15:47:47.038561 32485 net.cpp:84] Creating Layer pool5/2x2_s2
I0415 15:47:47.038564 32485 net.cpp:380] pool5/2x2_s2 <- conv8/3x3_s1
I0415 15:47:47.038568 32485 net.cpp:338] pool5/2x2_s2 -> pool5/2x2_s2
I0415 15:47:47.038573 32485 net.cpp:113] Setting up pool5/2x2_s2
I0415 15:47:47.038578 32485 net.cpp:120] Top shape: 64 512 7 7 (1605632)
I0415 15:47:47.038581 32485 layer_factory.hpp:74] Creating layer fc6-conv
I0415 15:47:47.038586 32485 net.cpp:84] Creating Layer fc6-conv
I0415 15:47:47.038589 32485 net.cpp:380] fc6-conv <- pool5/2x2_s2
I0415 15:47:47.038594 32485 net.cpp:338] fc6-conv -> fc6-conv
I0415 15:47:47.038597 32485 net.cpp:113] Setting up fc6-conv
I0415 15:47:48.112248 32485 net.cpp:120] Top shape: 64 4096 1 1 (262144)
I0415 15:47:48.112282 32485 layer_factory.hpp:74] Creating layer fc7-conv
I0415 15:47:48.112292 32485 net.cpp:84] Creating Layer fc7-conv
I0415 15:47:48.112295 32485 net.cpp:380] fc7-conv <- fc6-conv
I0415 15:47:48.112301 32485 net.cpp:338] fc7-conv -> fc7-conv
I0415 15:47:48.112309 32485 net.cpp:113] Setting up fc7-conv
I0415 15:47:48.359241 32485 net.cpp:120] Top shape: 64 4096 1 1 (262144)
I0415 15:47:48.359268 32485 layer_factory.hpp:74] Creating layer fc8-conv
I0415 15:47:48.359277 32485 net.cpp:84] Creating Layer fc8-conv
I0415 15:47:48.359282 32485 net.cpp:380] fc8-conv <- fc7-conv
I0415 15:47:48.359288 32485 net.cpp:338] fc8-conv -> fc8
I0415 15:47:48.359298 32485 net.cpp:113] Setting up fc8-conv
I0415 15:47:48.415319 32485 net.cpp:120] Top shape: 64 1000 1 1 (64000)
I0415 15:47:48.415345 32485 net.cpp:169] fc8-conv does not need backward computation.
I0415 15:47:48.415349 32485 net.cpp:169] fc7-conv does not need backward computation.
I0415 15:47:48.415351 32485 net.cpp:169] fc6-conv does not need backward computation.
I0415 15:47:48.415354 32485 net.cpp:169] pool5/2x2_s2 does not need backward computation.
I0415 15:47:48.415357 32485 net.cpp:169] conv8/relu does not need backward computation.
I0415 15:47:48.415360 32485 net.cpp:169] conv8/3x3_s1 does not need backward computation.
I0415 15:47:48.415362 32485 net.cpp:169] conv7/relu does not need backward computation.
I0415 15:47:48.415365 32485 net.cpp:169] conv7/3x3_s1 does not need backward computation.
I0415 15:47:48.415367 32485 net.cpp:169] pool4/2x2_s2 does not need backward computation.
I0415 15:47:48.415370 32485 net.cpp:169] conv6/relu does not need backward computation.
I0415 15:47:48.415374 32485 net.cpp:169] conv6/3x3_s1 does not need backward computation.
I0415 15:47:48.415384 32485 net.cpp:169] conv5/relu does not need backward computation.
I0415 15:47:48.415386 32485 net.cpp:169] conv5/3x3_s1 does not need backward computation.
I0415 15:47:48.415390 32485 net.cpp:169] pool3/2x2_s2 does not need backward computation.
I0415 15:47:48.415392 32485 net.cpp:169] conv4/relu does not need backward computation.
I0415 15:47:48.415395 32485 net.cpp:169] conv4/3x3_s1 does not need backward computation.
I0415 15:47:48.415397 32485 net.cpp:169] conv3/relu does not need backward computation.
I0415 15:47:48.415400 32485 net.cpp:169] conv3/3x3_s1 does not need backward computation.
I0415 15:47:48.415402 32485 net.cpp:169] pool2/2x2_s2 does not need backward computation.
I0415 15:47:48.415405 32485 net.cpp:169] conv2/relu does not need backward computation.
I0415 15:47:48.415408 32485 net.cpp:169] conv2/3x3_s1 does not need backward computation.
I0415 15:47:48.415410 32485 net.cpp:169] pool1/2x2_s2 does not need backward computation.
I0415 15:47:48.415413 32485 net.cpp:169] conv1/relu does not need backward computation.
I0415 15:47:48.415416 32485 net.cpp:169] conv1/3x3_s1 does not need backward computation.
I0415 15:47:48.415421 32485 net.cpp:205] This network produces output fc8
I0415 15:47:48.415444 32485 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0415 15:47:48.415452 32485 net.cpp:217] Network initialization done.
I0415 15:47:48.415455 32485 net.cpp:218] Memory required for data: 4148766720
I0415 15:47:48.415534 32485 caffe.cpp:224] Performing Forward
I0415 15:47:49.082494 32485 caffe.cpp:229] Initial loss: 0
I0415 15:47:49.082531 32485 caffe.cpp:230] Performing Backward
I0415 15:47:50.170670 32485 caffe.cpp:238] *** Benchmark begins ***
I0415 15:47:50.170682 32485 caffe.cpp:239] Testing for 10 iterations.
I0415 15:47:52.332433 32485 caffe.cpp:270] Iteration: 1 forward-backward time: 1917.37 ms.
I0415 15:47:54.251273 32485 caffe.cpp:270] Iteration: 2 forward-backward time: 1918.77 ms.
I0415 15:47:56.170455 32485 caffe.cpp:270] Iteration: 3 forward-backward time: 1919.12 ms.
I0415 15:47:58.090082 32485 caffe.cpp:270] Iteration: 4 forward-backward time: 1919.56 ms.
I0415 15:48:00.008507 32485 caffe.cpp:270] Iteration: 5 forward-backward time: 1918.36 ms.
I0415 15:48:01.928779 32485 caffe.cpp:270] Iteration: 6 forward-backward time: 1920.21 ms.
I0415 15:48:03.851305 32485 caffe.cpp:270] Iteration: 7 forward-backward time: 1922.46 ms.
I0415 15:48:05.772460 32485 caffe.cpp:270] Iteration: 8 forward-backward time: 1921.08 ms.
I0415 15:48:07.692117 32485 caffe.cpp:270] Iteration: 9 forward-backward time: 1919.59 ms.
I0415 15:48:09.612454 32485 caffe.cpp:270] Iteration: 10 forward-backward time: 1920.27 ms.
I0415 15:48:09.612470 32485 caffe.cpp:273] Average time per layer: 
I0415 15:48:09.612473 32485 caffe.cpp:276] conv1/3x3_s1	forward: 18.7571 ms.
I0415 15:48:09.612478 32485 caffe.cpp:279] conv1/3x3_s1	backward: 76.1804 ms.
I0415 15:48:09.612481 32485 caffe.cpp:276] conv1/relu	forward: 6.36868 ms.
I0415 15:48:09.612484 32485 caffe.cpp:279] conv1/relu	backward: 9.44937 ms.
I0415 15:48:09.612488 32485 caffe.cpp:276] pool1/2x2_s2	forward: 4.89492 ms.
I0415 15:48:09.612490 32485 caffe.cpp:279] pool1/2x2_s2	backward: 25.2688 ms.
I0415 15:48:09.612493 32485 caffe.cpp:276] conv2/3x3_s1	forward: 37.3801 ms.
I0415 15:48:09.612496 32485 caffe.cpp:279] conv2/3x3_s1	backward: 130.697 ms.
I0415 15:48:09.612500 32485 caffe.cpp:276] conv2/relu	forward: 3.18894 ms.
I0415 15:48:09.612503 32485 caffe.cpp:279] conv2/relu	backward: 4.73046 ms.
I0415 15:48:09.612505 32485 caffe.cpp:276] pool2/2x2_s2	forward: 2.48832 ms.
I0415 15:48:09.612509 32485 caffe.cpp:279] pool2/2x2_s2	backward: 12.6367 ms.
I0415 15:48:09.612511 32485 caffe.cpp:276] conv3/3x3_s1	forward: 30.9601 ms.
I0415 15:48:09.612515 32485 caffe.cpp:279] conv3/3x3_s1	backward: 69.6427 ms.
I0415 15:48:09.612519 32485 caffe.cpp:276] conv3/relu	forward: 1.62724 ms.
I0415 15:48:09.612521 32485 caffe.cpp:279] conv3/relu	backward: 2.40794 ms.
I0415 15:48:09.612524 32485 caffe.cpp:276] conv4/3x3_s1	forward: 56.5702 ms.
I0415 15:48:09.612527 32485 caffe.cpp:279] conv4/3x3_s1	backward: 111.434 ms.
I0415 15:48:09.612537 32485 caffe.cpp:276] conv4/relu	forward: 1.62816 ms.
I0415 15:48:09.612541 32485 caffe.cpp:279] conv4/relu	backward: 2.41459 ms.
I0415 15:48:09.612543 32485 caffe.cpp:276] pool3/2x2_s2	forward: 1.25255 ms.
I0415 15:48:09.612546 32485 caffe.cpp:279] pool3/2x2_s2	backward: 6.42734 ms.
I0415 15:48:09.612550 32485 caffe.cpp:276] conv5/3x3_s1	forward: 26.1151 ms.
I0415 15:48:09.612553 32485 caffe.cpp:279] conv5/3x3_s1	backward: 59.1319 ms.
I0415 15:48:09.612556 32485 caffe.cpp:276] conv5/relu	forward: 0.81552 ms.
I0415 15:48:09.612560 32485 caffe.cpp:279] conv5/relu	backward: 1.20617 ms.
I0415 15:48:09.612562 32485 caffe.cpp:276] conv6/3x3_s1	forward: 50.0548 ms.
I0415 15:48:09.612565 32485 caffe.cpp:279] conv6/3x3_s1	backward: 106.668 ms.
I0415 15:48:09.612568 32485 caffe.cpp:276] conv6/relu	forward: 0.815318 ms.
I0415 15:48:09.612571 32485 caffe.cpp:279] conv6/relu	backward: 1.21057 ms.
I0415 15:48:09.612575 32485 caffe.cpp:276] pool4/2x2_s2	forward: 0.642774 ms.
I0415 15:48:09.612577 32485 caffe.cpp:279] pool4/2x2_s2	backward: 3.21996 ms.
I0415 15:48:09.612581 32485 caffe.cpp:276] conv7/3x3_s1	forward: 39.9336 ms.
I0415 15:48:09.612583 32485 caffe.cpp:279] conv7/3x3_s1	backward: 59.6603 ms.
I0415 15:48:09.612586 32485 caffe.cpp:276] conv7/relu	forward: 0.207264 ms.
I0415 15:48:09.612589 32485 caffe.cpp:279] conv7/relu	backward: 0.304634 ms.
I0415 15:48:09.612592 32485 caffe.cpp:276] conv8/3x3_s1	forward: 40.0646 ms.
I0415 15:48:09.612596 32485 caffe.cpp:279] conv8/3x3_s1	backward: 59.6112 ms.
I0415 15:48:09.612598 32485 caffe.cpp:276] conv8/relu	forward: 0.207062 ms.
I0415 15:48:09.612601 32485 caffe.cpp:279] conv8/relu	backward: 0.306586 ms.
I0415 15:48:09.612604 32485 caffe.cpp:276] pool5/2x2_s2	forward: 0.180838 ms.
I0415 15:48:09.612607 32485 caffe.cpp:279] pool5/2x2_s2	backward: 0.819107 ms.
I0415 15:48:09.612609 32485 caffe.cpp:276]   fc6-conv	forward: 240.177 ms.
I0415 15:48:09.612613 32485 caffe.cpp:279]   fc6-conv	backward: 469.854 ms.
I0415 15:48:09.612617 32485 caffe.cpp:276]   fc7-conv	forward: 38.0485 ms.
I0415 15:48:09.612619 32485 caffe.cpp:279]   fc7-conv	backward: 73.2552 ms.
I0415 15:48:09.612622 32485 caffe.cpp:276]   fc8-conv	forward: 11.4768 ms.
I0415 15:48:09.612625 32485 caffe.cpp:279]   fc8-conv	backward: 18.9043 ms.
I0415 15:48:09.612637 32485 caffe.cpp:284] Average Forward pass: 614.032 ms.
I0415 15:48:09.612642 32485 caffe.cpp:286] Average Backward pass: 1305.63 ms.
I0415 15:48:09.612645 32485 caffe.cpp:288] Average Forward-Backward: 1919.72 ms.
I0415 15:48:09.612650 32485 caffe.cpp:290] Total Time: 19197.2 ms.
I0415 15:48:09.612653 32485 caffe.cpp:291] *** Benchmark ends ***
